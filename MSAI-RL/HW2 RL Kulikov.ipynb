{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rua4Az6SX9zH"
      },
      "source": [
        "# Deep Q-Network implementation.\n",
        "\n",
        "This homework shamelessly demands you to implement DQN — an approximate Q-learning algorithm with experience replay and target networks — and see if it works any better this way.\n",
        "\n",
        "Original paper:\n",
        "https://arxiv.org/pdf/1312.5602.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3YC7j-5YD4L"
      },
      "source": [
        "Acknowledgements for this homework to the [Practical_RL](https://github.com/yandexdataschool/Practical_RL) course team."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXWuyam-X9zP"
      },
      "source": [
        "**This notebook is the main notebook.** Another notebook is given for debug. (**homework_pytorch_main**). The tasks are similar and share most of the code. The main difference is in environments. In main notebook it can take some 2 hours for the agent to start improving so it seems reasonable to launch the algorithm on a simpler env first. In debug one it is CartPole and it will train in several minutes.\n",
        "\n",
        "**We suggest the following pipeline:** First implement debug notebook then implement the main one.\n",
        "\n",
        "**About evaluation:** All points are given for the main notebook with one exception: if agent fails to beat the threshold in main notebook you can get 1 pt (instead of 3 pts) for beating the threshold in debug notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCLFgMw9X9zS",
        "outputId": "d7eabe1c-8c29-4e33-fe0f-b8cae84dc2d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting virtual X frame buffer: Xvfb.\n"
          ]
        }
      ],
      "source": [
        "import sys, os\n",
        "if 'google.colab' in sys.modules and not os.path.exists('.setup_complete'):\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/setup_colab.sh -O- | bash\n",
        "        \n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/week04_approx_rl/atari_wrappers.py\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/week04_approx_rl/utils.py\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/week04_approx_rl/replay_buffer.py\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/week04_approx_rl/framebuffer.py\n",
        "\n",
        "    !touch .setup_complete\n",
        "\n",
        "# This code creates a virtual display to draw game images on.\n",
        "# It will have no effect if your machine has a monitor.\n",
        "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
        "    !bash ../xvfb start\n",
        "    os.environ['DISPLAY'] = ':1'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhBCDTlEX9zW"
      },
      "source": [
        "__Frameworks__ - we'll accept this homework in any deep learning framework. This particular notebook was designed for PyTorch, but you find it easy to adapt it to almost any Python-based deep learning framework."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXNJKIeGX9zZ"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkZstUwiX9za",
        "outputId": "b631a2c5-d31b-4178-a222-4db629ed54ef"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/ale_py/roms/__init__.py:89: DeprecationWarning: Automatic importing of atari-py roms won't be supported in future releases of ale-py. Please migrate over to using `ale-import-roms` OR an ALE-supported ROM package. To make this warning disappear you can run `ale-import-roms --import-from-pkg atari_py.atari_roms`.For more information see: https://github.com/mgbellemare/Arcade-Learning-Environment#rom-management\n",
            "  ROMS = resolve_roms()\n"
          ]
        }
      ],
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INCBRK_S8doB",
        "outputId": "09047720-c696-48e4-b1f1-bf0abd6fe8b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gym[atari] in /usr/local/lib/python3.8/dist-packages (0.25.2)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.8/dist-packages (from gym[atari]) (4.13.0)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.8/dist-packages (from gym[atari]) (1.21.6)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.8/dist-packages (from gym[atari]) (0.0.8)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from gym[atari]) (1.5.0)\n",
            "Requirement already satisfied: ale-py~=0.7.5 in /usr/local/lib/python3.8/dist-packages (from gym[atari]) (0.7.5)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from ale-py~=0.7.5->gym[atari]) (5.10.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.8.0->gym[atari]) (3.10.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install gym[atari]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZQ_Hhpg5hxJ",
        "outputId": "6f51d2ab-b800-4e76-e5da-9d62cdd40498"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EnvSpec(id='ALE/Tetris-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'tetris', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Tetris', version=5)\n",
            "EnvSpec(id='ALE/Tetris-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'tetris', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Tetris-ram', version=5)\n",
            "EnvSpec(id='ALE/Skiing-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'skiing', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Skiing', version=5)\n",
            "EnvSpec(id='ALE/Skiing-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'skiing', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Skiing-ram', version=5)\n",
            "EnvSpec(id='ALE/Boxing-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'boxing', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Boxing', version=5)\n",
            "EnvSpec(id='ALE/Boxing-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'boxing', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Boxing-ram', version=5)\n",
            "EnvSpec(id='ALE/Zaxxon-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'zaxxon', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Zaxxon', version=5)\n",
            "EnvSpec(id='ALE/Zaxxon-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'zaxxon', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Zaxxon-ram', version=5)\n",
            "EnvSpec(id='ALE/KeystoneKapers-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'keystone_kapers', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='KeystoneKapers', version=5)\n",
            "EnvSpec(id='ALE/KeystoneKapers-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'keystone_kapers', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='KeystoneKapers-ram', version=5)\n",
            "EnvSpec(id='ALE/Amidar-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'amidar', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Amidar', version=5)\n",
            "EnvSpec(id='ALE/Amidar-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'amidar', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Amidar-ram', version=5)\n",
            "EnvSpec(id='ALE/Krull-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'krull', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Krull', version=5)\n",
            "EnvSpec(id='ALE/Krull-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'krull', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Krull-ram', version=5)\n",
            "EnvSpec(id='ALE/KingKong-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'king_kong', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='KingKong', version=5)\n",
            "EnvSpec(id='ALE/KingKong-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'king_kong', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='KingKong-ram', version=5)\n",
            "EnvSpec(id='ALE/Koolaid-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'koolaid', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Koolaid', version=5)\n",
            "EnvSpec(id='ALE/Koolaid-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'koolaid', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Koolaid-ram', version=5)\n",
            "EnvSpec(id='ALE/Assault-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'assault', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Assault', version=5)\n",
            "EnvSpec(id='ALE/Assault-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'assault', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Assault-ram', version=5)\n",
            "EnvSpec(id='ALE/Tennis-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'tennis', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Tennis', version=5)\n",
            "EnvSpec(id='ALE/Tennis-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'tennis', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Tennis-ram', version=5)\n",
            "EnvSpec(id='ALE/Trondead-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'trondead', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Trondead', version=5)\n",
            "EnvSpec(id='ALE/Trondead-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'trondead', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Trondead-ram', version=5)\n",
            "EnvSpec(id='ALE/Hero-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'hero', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Hero', version=5)\n",
            "EnvSpec(id='ALE/Hero-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'hero', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Hero-ram', version=5)\n",
            "EnvSpec(id='ALE/Breakout-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'breakout', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Breakout', version=5)\n",
            "EnvSpec(id='ALE/Breakout-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'breakout', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Breakout-ram', version=5)\n",
            "EnvSpec(id='ALE/Enduro-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'enduro', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Enduro', version=5)\n",
            "EnvSpec(id='ALE/Enduro-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'enduro', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Enduro-ram', version=5)\n",
            "EnvSpec(id='ALE/MsPacman-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'ms_pacman', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='MsPacman', version=5)\n",
            "EnvSpec(id='ALE/MsPacman-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'ms_pacman', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='MsPacman-ram', version=5)\n",
            "EnvSpec(id='ALE/Seaquest-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'seaquest', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Seaquest', version=5)\n",
            "EnvSpec(id='ALE/Seaquest-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'seaquest', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Seaquest-ram', version=5)\n",
            "EnvSpec(id='ALE/MrDo-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'mr_do', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='MrDo', version=5)\n",
            "EnvSpec(id='ALE/MrDo-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'mr_do', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='MrDo-ram', version=5)\n",
            "EnvSpec(id='ALE/AirRaid-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'air_raid', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='AirRaid', version=5)\n",
            "EnvSpec(id='ALE/AirRaid-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'air_raid', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='AirRaid-ram', version=5)\n",
            "EnvSpec(id='ALE/BeamRider-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'beam_rider', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='BeamRider', version=5)\n",
            "EnvSpec(id='ALE/BeamRider-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'beam_rider', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='BeamRider-ram', version=5)\n",
            "EnvSpec(id='ALE/Centipede-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'centipede', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Centipede', version=5)\n",
            "EnvSpec(id='ALE/Centipede-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'centipede', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Centipede-ram', version=5)\n",
            "EnvSpec(id='ALE/Tutankham-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'tutankham', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Tutankham', version=5)\n",
            "EnvSpec(id='ALE/Tutankham-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'tutankham', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Tutankham-ram', version=5)\n",
            "EnvSpec(id='ALE/YarsRevenge-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'yars_revenge', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='YarsRevenge', version=5)\n",
            "EnvSpec(id='ALE/YarsRevenge-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'yars_revenge', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='YarsRevenge-ram', version=5)\n",
            "EnvSpec(id='ALE/ElevatorAction-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'elevator_action', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='ElevatorAction', version=5)\n",
            "EnvSpec(id='ALE/ElevatorAction-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'elevator_action', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='ElevatorAction-ram', version=5)\n",
            "EnvSpec(id='ALE/VideoPinball-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'video_pinball', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='VideoPinball', version=5)\n",
            "EnvSpec(id='ALE/VideoPinball-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'video_pinball', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='VideoPinball-ram', version=5)\n",
            "EnvSpec(id='ALE/Solaris-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'solaris', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Solaris', version=5)\n",
            "EnvSpec(id='ALE/Solaris-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'solaris', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Solaris-ram', version=5)\n",
            "EnvSpec(id='ALE/Kangaroo-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'kangaroo', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Kangaroo', version=5)\n",
            "EnvSpec(id='ALE/Kangaroo-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'kangaroo', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Kangaroo-ram', version=5)\n",
            "EnvSpec(id='ALE/LostLuggage-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'lost_luggage', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='LostLuggage', version=5)\n",
            "EnvSpec(id='ALE/LostLuggage-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'lost_luggage', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='LostLuggage-ram', version=5)\n",
            "EnvSpec(id='ALE/Robotank-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'robotank', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Robotank', version=5)\n",
            "EnvSpec(id='ALE/Robotank-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'robotank', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Robotank-ram', version=5)\n",
            "EnvSpec(id='ALE/SirLancelot-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'sir_lancelot', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='SirLancelot', version=5)\n",
            "EnvSpec(id='ALE/SirLancelot-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'sir_lancelot', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='SirLancelot-ram', version=5)\n",
            "EnvSpec(id='ALE/LaserGates-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'laser_gates', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='LaserGates', version=5)\n",
            "EnvSpec(id='ALE/LaserGates-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'laser_gates', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='LaserGates-ram', version=5)\n",
            "EnvSpec(id='ALE/Defender-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'defender', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Defender', version=5)\n",
            "EnvSpec(id='ALE/Defender-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'defender', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Defender-ram', version=5)\n",
            "EnvSpec(id='ALE/Berzerk-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'berzerk', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Berzerk', version=5)\n",
            "EnvSpec(id='ALE/Berzerk-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'berzerk', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Berzerk-ram', version=5)\n",
            "EnvSpec(id='ALE/Bowling-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'bowling', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Bowling', version=5)\n",
            "EnvSpec(id='ALE/Bowling-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'bowling', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Bowling-ram', version=5)\n",
            "EnvSpec(id='ALE/KungFuMaster-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'kung_fu_master', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='KungFuMaster', version=5)\n",
            "EnvSpec(id='ALE/KungFuMaster-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'kung_fu_master', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='KungFuMaster-ram', version=5)\n",
            "EnvSpec(id='ALE/Surround-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'surround', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Surround', version=5)\n",
            "EnvSpec(id='ALE/Surround-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'surround', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Surround-ram', version=5)\n",
            "EnvSpec(id='ALE/DoubleDunk-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'double_dunk', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='DoubleDunk', version=5)\n",
            "EnvSpec(id='ALE/DoubleDunk-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'double_dunk', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='DoubleDunk-ram', version=5)\n",
            "EnvSpec(id='ALE/Phoenix-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'phoenix', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Phoenix', version=5)\n",
            "EnvSpec(id='ALE/Phoenix-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'phoenix', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Phoenix-ram', version=5)\n",
            "EnvSpec(id='ALE/Pacman-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pacman', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Pacman', version=5)\n",
            "EnvSpec(id='ALE/Pacman-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pacman', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Pacman-ram', version=5)\n",
            "EnvSpec(id='ALE/Frostbite-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'frostbite', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Frostbite', version=5)\n",
            "EnvSpec(id='ALE/Frostbite-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'frostbite', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Frostbite-ram', version=5)\n",
            "EnvSpec(id='ALE/Gopher-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'gopher', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Gopher', version=5)\n",
            "EnvSpec(id='ALE/Gopher-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'gopher', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Gopher-ram', version=5)\n",
            "EnvSpec(id='ALE/Gravitar-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'gravitar', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Gravitar', version=5)\n",
            "EnvSpec(id='ALE/Gravitar-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'gravitar', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Gravitar-ram', version=5)\n",
            "EnvSpec(id='ALE/DemonAttack-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'demon_attack', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='DemonAttack', version=5)\n",
            "EnvSpec(id='ALE/DemonAttack-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'demon_attack', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='DemonAttack-ram', version=5)\n",
            "EnvSpec(id='ALE/Pong-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pong', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Pong', version=5)\n",
            "EnvSpec(id='ALE/Pong-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pong', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Pong-ram', version=5)\n",
            "EnvSpec(id='ALE/SpaceInvaders-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'space_invaders', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='SpaceInvaders', version=5)\n",
            "EnvSpec(id='ALE/SpaceInvaders-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'space_invaders', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='SpaceInvaders-ram', version=5)\n",
            "EnvSpec(id='ALE/Freeway-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'freeway', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Freeway', version=5)\n",
            "EnvSpec(id='ALE/Freeway-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'freeway', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Freeway-ram', version=5)\n",
            "EnvSpec(id='ALE/Pooyan-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pooyan', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Pooyan', version=5)\n",
            "EnvSpec(id='ALE/Pooyan-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pooyan', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Pooyan-ram', version=5)\n",
            "EnvSpec(id='ALE/TimePilot-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'time_pilot', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='TimePilot', version=5)\n",
            "EnvSpec(id='ALE/TimePilot-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'time_pilot', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='TimePilot-ram', version=5)\n",
            "EnvSpec(id='ALE/Asterix-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'asterix', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Asterix', version=5)\n",
            "EnvSpec(id='ALE/Asterix-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'asterix', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Asterix-ram', version=5)\n",
            "EnvSpec(id='ALE/PrivateEye-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'private_eye', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='PrivateEye', version=5)\n",
            "EnvSpec(id='ALE/PrivateEye-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'private_eye', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='PrivateEye-ram', version=5)\n",
            "EnvSpec(id='ALE/CrazyClimber-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'crazy_climber', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='CrazyClimber', version=5)\n",
            "EnvSpec(id='ALE/CrazyClimber-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'crazy_climber', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='CrazyClimber-ram', version=5)\n",
            "EnvSpec(id='ALE/Jamesbond-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'jamesbond', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Jamesbond', version=5)\n",
            "EnvSpec(id='ALE/Jamesbond-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'jamesbond', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Jamesbond-ram', version=5)\n",
            "EnvSpec(id='ALE/Venture-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'venture', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Venture', version=5)\n",
            "EnvSpec(id='ALE/Venture-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'venture', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Venture-ram', version=5)\n",
            "EnvSpec(id='ALE/JourneyEscape-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'journey_escape', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='JourneyEscape', version=5)\n",
            "EnvSpec(id='ALE/JourneyEscape-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'journey_escape', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='JourneyEscape-ram', version=5)\n",
            "EnvSpec(id='ALE/NameThisGame-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'name_this_game', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='NameThisGame', version=5)\n",
            "EnvSpec(id='ALE/NameThisGame-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'name_this_game', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='NameThisGame-ram', version=5)\n",
            "EnvSpec(id='ALE/Frogger-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'frogger', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Frogger', version=5)\n",
            "EnvSpec(id='ALE/Frogger-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'frogger', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Frogger-ram', version=5)\n",
            "EnvSpec(id='ALE/Galaxian-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'galaxian', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Galaxian', version=5)\n",
            "EnvSpec(id='ALE/Galaxian-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'galaxian', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Galaxian-ram', version=5)\n",
            "EnvSpec(id='ALE/Atlantis-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'atlantis', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Atlantis', version=5)\n",
            "EnvSpec(id='ALE/Atlantis-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'atlantis', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Atlantis-ram', version=5)\n",
            "EnvSpec(id='ALE/FishingDerby-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'fishing_derby', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='FishingDerby', version=5)\n",
            "EnvSpec(id='ALE/FishingDerby-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'fishing_derby', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='FishingDerby-ram', version=5)\n",
            "EnvSpec(id='ALE/ChopperCommand-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'chopper_command', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='ChopperCommand', version=5)\n",
            "EnvSpec(id='ALE/ChopperCommand-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'chopper_command', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='ChopperCommand-ram', version=5)\n",
            "EnvSpec(id='ALE/BankHeist-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'bank_heist', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='BankHeist', version=5)\n",
            "EnvSpec(id='ALE/BankHeist-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'bank_heist', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='BankHeist-ram', version=5)\n",
            "EnvSpec(id='ALE/Pitfall-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pitfall', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Pitfall', version=5)\n",
            "EnvSpec(id='ALE/Pitfall-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pitfall', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Pitfall-ram', version=5)\n",
            "EnvSpec(id='ALE/WizardOfWor-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'wizard_of_wor', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='WizardOfWor', version=5)\n",
            "EnvSpec(id='ALE/WizardOfWor-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'wizard_of_wor', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='WizardOfWor-ram', version=5)\n",
            "EnvSpec(id='ALE/Riverraid-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'riverraid', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Riverraid', version=5)\n",
            "EnvSpec(id='ALE/Riverraid-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'riverraid', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Riverraid-ram', version=5)\n",
            "EnvSpec(id='ALE/Alien-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'alien', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Alien', version=5)\n",
            "EnvSpec(id='ALE/Alien-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'alien', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Alien-ram', version=5)\n",
            "EnvSpec(id='ALE/BattleZone-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'battle_zone', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='BattleZone', version=5)\n",
            "EnvSpec(id='ALE/BattleZone-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'battle_zone', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='BattleZone-ram', version=5)\n",
            "EnvSpec(id='ALE/StarGunner-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'star_gunner', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='StarGunner', version=5)\n",
            "EnvSpec(id='ALE/StarGunner-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'star_gunner', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='StarGunner-ram', version=5)\n",
            "EnvSpec(id='ALE/Kaboom-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'kaboom', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Kaboom', version=5)\n",
            "EnvSpec(id='ALE/Kaboom-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'kaboom', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Kaboom-ram', version=5)\n",
            "EnvSpec(id='ALE/DonkeyKong-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'donkey_kong', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='DonkeyKong', version=5)\n",
            "EnvSpec(id='ALE/DonkeyKong-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'donkey_kong', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='DonkeyKong-ram', version=5)\n",
            "EnvSpec(id='ALE/UpNDown-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'up_n_down', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='UpNDown', version=5)\n",
            "EnvSpec(id='ALE/UpNDown-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'up_n_down', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='UpNDown-ram', version=5)\n",
            "EnvSpec(id='ALE/Qbert-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'qbert', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Qbert', version=5)\n",
            "EnvSpec(id='ALE/Qbert-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'qbert', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Qbert-ram', version=5)\n",
            "EnvSpec(id='ALE/Carnival-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'carnival', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Carnival', version=5)\n",
            "EnvSpec(id='ALE/Carnival-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'carnival', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Carnival-ram', version=5)\n",
            "EnvSpec(id='ALE/Adventure-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'adventure', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Adventure', version=5)\n",
            "EnvSpec(id='ALE/Adventure-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'adventure', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Adventure-ram', version=5)\n",
            "EnvSpec(id='ALE/IceHockey-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'ice_hockey', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='IceHockey', version=5)\n",
            "EnvSpec(id='ALE/IceHockey-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'ice_hockey', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='IceHockey-ram', version=5)\n",
            "EnvSpec(id='ALE/Asteroids-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'asteroids', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Asteroids', version=5)\n",
            "EnvSpec(id='ALE/Asteroids-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'asteroids', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Asteroids-ram', version=5)\n",
            "EnvSpec(id='ALE/MontezumaRevenge-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'montezuma_revenge', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='MontezumaRevenge', version=5)\n",
            "EnvSpec(id='ALE/MontezumaRevenge-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'montezuma_revenge', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='MontezumaRevenge-ram', version=5)\n",
            "EnvSpec(id='Adventure-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'adventure', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Adventure', version=0)\n",
            "EnvSpec(id='AdventureDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'adventure', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='AdventureDeterministic', version=0)\n",
            "EnvSpec(id='AdventureNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'adventure', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='AdventureNoFrameskip', version=0)\n",
            "EnvSpec(id='Adventure-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'adventure', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Adventure', version=4)\n",
            "EnvSpec(id='AdventureDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'adventure', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='AdventureDeterministic', version=4)\n",
            "EnvSpec(id='AdventureNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'adventure', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='AdventureNoFrameskip', version=4)\n",
            "EnvSpec(id='Adventure-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'adventure', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Adventure-ram', version=0)\n",
            "EnvSpec(id='Adventure-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'adventure', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Adventure-ramDeterministic', version=0)\n",
            "EnvSpec(id='Adventure-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'adventure', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Adventure-ramNoFrameskip', version=0)\n",
            "EnvSpec(id='Adventure-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'adventure', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Adventure-ram', version=4)\n",
            "EnvSpec(id='Adventure-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'adventure', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Adventure-ramDeterministic', version=4)\n",
            "EnvSpec(id='Adventure-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'adventure', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Adventure-ramNoFrameskip', version=4)\n",
            "EnvSpec(id='AirRaid-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'air_raid', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='AirRaid', version=0)\n",
            "EnvSpec(id='AirRaidDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'air_raid', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='AirRaidDeterministic', version=0)\n",
            "EnvSpec(id='AirRaidNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'air_raid', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='AirRaidNoFrameskip', version=0)\n",
            "EnvSpec(id='AirRaid-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'air_raid', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='AirRaid', version=4)\n",
            "EnvSpec(id='AirRaidDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'air_raid', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='AirRaidDeterministic', version=4)\n",
            "EnvSpec(id='AirRaidNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'air_raid', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='AirRaidNoFrameskip', version=4)\n",
            "EnvSpec(id='AirRaid-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'air_raid', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='AirRaid-ram', version=0)\n",
            "EnvSpec(id='AirRaid-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'air_raid', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='AirRaid-ramDeterministic', version=0)\n",
            "EnvSpec(id='AirRaid-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'air_raid', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='AirRaid-ramNoFrameskip', version=0)\n",
            "EnvSpec(id='AirRaid-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'air_raid', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='AirRaid-ram', version=4)\n",
            "EnvSpec(id='AirRaid-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'air_raid', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='AirRaid-ramDeterministic', version=4)\n",
            "EnvSpec(id='AirRaid-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'air_raid', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='AirRaid-ramNoFrameskip', version=4)\n",
            "EnvSpec(id='Alien-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'alien', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Alien', version=0)\n",
            "EnvSpec(id='AlienDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'alien', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='AlienDeterministic', version=0)\n",
            "EnvSpec(id='AlienNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'alien', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='AlienNoFrameskip', version=0)\n",
            "EnvSpec(id='Alien-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'alien', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Alien', version=4)\n",
            "EnvSpec(id='AlienDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'alien', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='AlienDeterministic', version=4)\n",
            "EnvSpec(id='AlienNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'alien', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='AlienNoFrameskip', version=4)\n",
            "EnvSpec(id='Alien-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'alien', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Alien-ram', version=0)\n",
            "EnvSpec(id='Alien-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'alien', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Alien-ramDeterministic', version=0)\n",
            "EnvSpec(id='Alien-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'alien', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Alien-ramNoFrameskip', version=0)\n",
            "EnvSpec(id='Alien-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'alien', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Alien-ram', version=4)\n",
            "EnvSpec(id='Alien-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'alien', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Alien-ramDeterministic', version=4)\n",
            "EnvSpec(id='Alien-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'alien', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Alien-ramNoFrameskip', version=4)\n",
            "EnvSpec(id='Amidar-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'amidar', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Amidar', version=0)\n",
            "EnvSpec(id='AmidarDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'amidar', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='AmidarDeterministic', version=0)\n",
            "EnvSpec(id='AmidarNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'amidar', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='AmidarNoFrameskip', version=0)\n",
            "EnvSpec(id='Amidar-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'amidar', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Amidar', version=4)\n",
            "EnvSpec(id='AmidarDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'amidar', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='AmidarDeterministic', version=4)\n",
            "EnvSpec(id='AmidarNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'amidar', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='AmidarNoFrameskip', version=4)\n",
            "EnvSpec(id='Amidar-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'amidar', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Amidar-ram', version=0)\n",
            "EnvSpec(id='Amidar-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'amidar', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Amidar-ramDeterministic', version=0)\n",
            "EnvSpec(id='Amidar-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'amidar', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Amidar-ramNoFrameskip', version=0)\n",
            "EnvSpec(id='Amidar-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'amidar', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Amidar-ram', version=4)\n",
            "EnvSpec(id='Amidar-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'amidar', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Amidar-ramDeterministic', version=4)\n",
            "EnvSpec(id='Amidar-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'amidar', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Amidar-ramNoFrameskip', version=4)\n",
            "EnvSpec(id='Assault-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'assault', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Assault', version=0)\n",
            "EnvSpec(id='AssaultDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'assault', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='AssaultDeterministic', version=0)\n",
            "EnvSpec(id='AssaultNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'assault', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='AssaultNoFrameskip', version=0)\n",
            "EnvSpec(id='Assault-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'assault', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Assault', version=4)\n",
            "EnvSpec(id='AssaultDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'assault', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='AssaultDeterministic', version=4)\n",
            "EnvSpec(id='AssaultNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'assault', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='AssaultNoFrameskip', version=4)\n",
            "EnvSpec(id='Assault-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'assault', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Assault-ram', version=0)\n",
            "EnvSpec(id='Assault-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'assault', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Assault-ramDeterministic', version=0)\n",
            "EnvSpec(id='Assault-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'assault', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Assault-ramNoFrameskip', version=0)\n",
            "EnvSpec(id='Assault-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'assault', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Assault-ram', version=4)\n",
            "EnvSpec(id='Assault-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'assault', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Assault-ramDeterministic', version=4)\n",
            "EnvSpec(id='Assault-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'assault', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Assault-ramNoFrameskip', version=4)\n",
            "EnvSpec(id='Asterix-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'asterix', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Asterix', version=0)\n",
            "EnvSpec(id='AsterixDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'asterix', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='AsterixDeterministic', version=0)\n",
            "EnvSpec(id='AsterixNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'asterix', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='AsterixNoFrameskip', version=0)\n",
            "EnvSpec(id='Asterix-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'asterix', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Asterix', version=4)\n",
            "EnvSpec(id='AsterixDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'asterix', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='AsterixDeterministic', version=4)\n",
            "EnvSpec(id='AsterixNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'asterix', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='AsterixNoFrameskip', version=4)\n",
            "EnvSpec(id='Asterix-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'asterix', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Asterix-ram', version=0)\n",
            "EnvSpec(id='Asterix-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'asterix', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Asterix-ramDeterministic', version=0)\n",
            "EnvSpec(id='Asterix-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'asterix', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Asterix-ramNoFrameskip', version=0)\n",
            "EnvSpec(id='Asterix-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'asterix', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Asterix-ram', version=4)\n",
            "EnvSpec(id='Asterix-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'asterix', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Asterix-ramDeterministic', version=4)\n",
            "EnvSpec(id='Asterix-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'asterix', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Asterix-ramNoFrameskip', version=4)\n",
            "EnvSpec(id='Asteroids-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'asteroids', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Asteroids', version=0)\n",
            "EnvSpec(id='AsteroidsDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'asteroids', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='AsteroidsDeterministic', version=0)\n",
            "EnvSpec(id='AsteroidsNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'asteroids', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='AsteroidsNoFrameskip', version=0)\n",
            "EnvSpec(id='Asteroids-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'asteroids', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Asteroids', version=4)\n",
            "EnvSpec(id='AsteroidsDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'asteroids', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='AsteroidsDeterministic', version=4)\n",
            "EnvSpec(id='AsteroidsNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'asteroids', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='AsteroidsNoFrameskip', version=4)\n",
            "EnvSpec(id='Asteroids-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'asteroids', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Asteroids-ram', version=0)\n",
            "EnvSpec(id='Asteroids-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'asteroids', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Asteroids-ramDeterministic', version=0)\n",
            "EnvSpec(id='Asteroids-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'asteroids', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Asteroids-ramNoFrameskip', version=0)\n",
            "EnvSpec(id='Asteroids-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'asteroids', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Asteroids-ram', version=4)\n",
            "EnvSpec(id='Asteroids-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'asteroids', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Asteroids-ramDeterministic', version=4)\n",
            "EnvSpec(id='Asteroids-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'asteroids', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Asteroids-ramNoFrameskip', version=4)\n",
            "EnvSpec(id='Atlantis-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'atlantis', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Atlantis', version=0)\n",
            "EnvSpec(id='AtlantisDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'atlantis', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='AtlantisDeterministic', version=0)\n",
            "EnvSpec(id='AtlantisNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'atlantis', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='AtlantisNoFrameskip', version=0)\n",
            "EnvSpec(id='Atlantis-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'atlantis', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Atlantis', version=4)\n",
            "EnvSpec(id='AtlantisDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'atlantis', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='AtlantisDeterministic', version=4)\n",
            "EnvSpec(id='AtlantisNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'atlantis', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='AtlantisNoFrameskip', version=4)\n",
            "EnvSpec(id='Atlantis-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'atlantis', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Atlantis-ram', version=0)\n",
            "EnvSpec(id='Atlantis-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'atlantis', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Atlantis-ramDeterministic', version=0)\n",
            "EnvSpec(id='Atlantis-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'atlantis', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Atlantis-ramNoFrameskip', version=0)\n",
            "EnvSpec(id='Atlantis-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'atlantis', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Atlantis-ram', version=4)\n",
            "EnvSpec(id='Atlantis-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'atlantis', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Atlantis-ramDeterministic', version=4)\n",
            "EnvSpec(id='Atlantis-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'atlantis', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Atlantis-ramNoFrameskip', version=4)\n",
            "EnvSpec(id='BankHeist-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'bank_heist', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='BankHeist', version=0)\n",
            "EnvSpec(id='BankHeistDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'bank_heist', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='BankHeistDeterministic', version=0)\n",
            "EnvSpec(id='BankHeistNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'bank_heist', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='BankHeistNoFrameskip', version=0)\n",
            "EnvSpec(id='BankHeist-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'bank_heist', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='BankHeist', version=4)\n",
            "EnvSpec(id='BankHeistDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'bank_heist', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='BankHeistDeterministic', version=4)\n",
            "EnvSpec(id='BankHeistNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'bank_heist', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='BankHeistNoFrameskip', version=4)\n",
            "EnvSpec(id='BankHeist-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'bank_heist', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='BankHeist-ram', version=0)\n",
            "EnvSpec(id='BankHeist-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'bank_heist', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='BankHeist-ramDeterministic', version=0)\n",
            "EnvSpec(id='BankHeist-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'bank_heist', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='BankHeist-ramNoFrameskip', version=0)\n",
            "EnvSpec(id='BankHeist-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'bank_heist', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='BankHeist-ram', version=4)\n",
            "EnvSpec(id='BankHeist-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'bank_heist', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='BankHeist-ramDeterministic', version=4)\n",
            "EnvSpec(id='BankHeist-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'bank_heist', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='BankHeist-ramNoFrameskip', version=4)\n",
            "EnvSpec(id='BattleZone-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'battle_zone', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='BattleZone', version=0)\n",
            "EnvSpec(id='BattleZoneDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'battle_zone', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='BattleZoneDeterministic', version=0)\n",
            "EnvSpec(id='BattleZoneNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'battle_zone', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='BattleZoneNoFrameskip', version=0)\n",
            "EnvSpec(id='BattleZone-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'battle_zone', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='BattleZone', version=4)\n",
            "EnvSpec(id='BattleZoneDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'battle_zone', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='BattleZoneDeterministic', version=4)\n",
            "EnvSpec(id='BattleZoneNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'battle_zone', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='BattleZoneNoFrameskip', version=4)\n",
            "EnvSpec(id='BattleZone-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'battle_zone', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='BattleZone-ram', version=0)\n",
            "EnvSpec(id='BattleZone-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'battle_zone', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='BattleZone-ramDeterministic', version=0)\n",
            "EnvSpec(id='BattleZone-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'battle_zone', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='BattleZone-ramNoFrameskip', version=0)\n",
            "EnvSpec(id='BattleZone-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'battle_zone', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='BattleZone-ram', version=4)\n",
            "EnvSpec(id='BattleZone-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'battle_zone', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='BattleZone-ramDeterministic', version=4)\n",
            "EnvSpec(id='BattleZone-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'battle_zone', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='BattleZone-ramNoFrameskip', version=4)\n",
            "EnvSpec(id='BeamRider-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'beam_rider', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='BeamRider', version=0)\n",
            "EnvSpec(id='BeamRiderDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'beam_rider', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='BeamRiderDeterministic', version=0)\n",
            "EnvSpec(id='BeamRiderNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'beam_rider', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='BeamRiderNoFrameskip', version=0)\n",
            "EnvSpec(id='BeamRider-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'beam_rider', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='BeamRider', version=4)\n",
            "EnvSpec(id='BeamRiderDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'beam_rider', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='BeamRiderDeterministic', version=4)\n",
            "EnvSpec(id='BeamRiderNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'beam_rider', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='BeamRiderNoFrameskip', version=4)\n",
            "EnvSpec(id='BeamRider-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'beam_rider', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='BeamRider-ram', version=0)\n",
            "EnvSpec(id='BeamRider-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'beam_rider', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='BeamRider-ramDeterministic', version=0)\n",
            "EnvSpec(id='BeamRider-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'beam_rider', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='BeamRider-ramNoFrameskip', version=0)\n",
            "EnvSpec(id='BeamRider-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'beam_rider', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='BeamRider-ram', version=4)\n",
            "EnvSpec(id='BeamRider-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'beam_rider', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='BeamRider-ramDeterministic', version=4)\n",
            "EnvSpec(id='BeamRider-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'beam_rider', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='BeamRider-ramNoFrameskip', version=4)\n",
            "EnvSpec(id='Berzerk-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'berzerk', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Berzerk', version=0)\n",
            "EnvSpec(id='BerzerkDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'berzerk', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='BerzerkDeterministic', version=0)\n",
            "EnvSpec(id='BerzerkNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'berzerk', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='BerzerkNoFrameskip', version=0)\n",
            "EnvSpec(id='Berzerk-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'berzerk', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Berzerk', version=4)\n",
            "EnvSpec(id='BerzerkDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'berzerk', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='BerzerkDeterministic', version=4)\n",
            "EnvSpec(id='BerzerkNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'berzerk', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='BerzerkNoFrameskip', version=4)\n",
            "EnvSpec(id='Berzerk-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'berzerk', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Berzerk-ram', version=0)\n",
            "EnvSpec(id='Berzerk-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'berzerk', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Berzerk-ramDeterministic', version=0)\n",
            "EnvSpec(id='Berzerk-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'berzerk', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Berzerk-ramNoFrameskip', version=0)\n",
            "EnvSpec(id='Berzerk-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'berzerk', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Berzerk-ram', version=4)\n",
            "EnvSpec(id='Berzerk-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'berzerk', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Berzerk-ramDeterministic', version=4)\n",
            "EnvSpec(id='Berzerk-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'berzerk', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Berzerk-ramNoFrameskip', version=4)\n",
            "EnvSpec(id='Bowling-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'bowling', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Bowling', version=0)\n",
            "EnvSpec(id='BowlingDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'bowling', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='BowlingDeterministic', version=0)\n",
            "EnvSpec(id='BowlingNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'bowling', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='BowlingNoFrameskip', version=0)\n",
            "EnvSpec(id='Bowling-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'bowling', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Bowling', version=4)\n",
            "EnvSpec(id='BowlingDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'bowling', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='BowlingDeterministic', version=4)\n",
            "EnvSpec(id='BowlingNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'bowling', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='BowlingNoFrameskip', version=4)\n",
            "EnvSpec(id='Bowling-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'bowling', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Bowling-ram', version=0)\n",
            "EnvSpec(id='Bowling-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'bowling', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Bowling-ramDeterministic', version=0)\n",
            "EnvSpec(id='Bowling-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'bowling', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Bowling-ramNoFrameskip', version=0)\n",
            "EnvSpec(id='Bowling-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'bowling', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Bowling-ram', version=4)\n",
            "EnvSpec(id='Bowling-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'bowling', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Bowling-ramDeterministic', version=4)\n",
            "EnvSpec(id='Bowling-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'bowling', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Bowling-ramNoFrameskip', version=4)\n",
            "EnvSpec(id='Boxing-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'boxing', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Boxing', version=0)\n",
            "EnvSpec(id='BoxingDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'boxing', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='BoxingDeterministic', version=0)\n",
            "EnvSpec(id='BoxingNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'boxing', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='BoxingNoFrameskip', version=0)\n",
            "EnvSpec(id='Boxing-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'boxing', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Boxing', version=4)\n",
            "EnvSpec(id='BoxingDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'boxing', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='BoxingDeterministic', version=4)\n",
            "EnvSpec(id='BoxingNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'boxing', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='BoxingNoFrameskip', version=4)\n",
            "EnvSpec(id='Boxing-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'boxing', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Boxing-ram', version=0)\n",
            "EnvSpec(id='Boxing-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'boxing', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Boxing-ramDeterministic', version=0)\n",
            "EnvSpec(id='Boxing-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'boxing', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Boxing-ramNoFrameskip', version=0)\n",
            "EnvSpec(id='Boxing-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'boxing', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Boxing-ram', version=4)\n",
            "EnvSpec(id='Boxing-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'boxing', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Boxing-ramDeterministic', version=4)\n",
            "EnvSpec(id='Boxing-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'boxing', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Boxing-ramNoFrameskip', version=4)\n",
            "EnvSpec(id='Breakout-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'breakout', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Breakout', version=0)\n",
            "EnvSpec(id='BreakoutDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'breakout', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='BreakoutDeterministic', version=0)\n",
            "EnvSpec(id='BreakoutNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'breakout', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='BreakoutNoFrameskip', version=0)\n",
            "EnvSpec(id='Breakout-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'breakout', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Breakout', version=4)\n",
            "EnvSpec(id='BreakoutDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'breakout', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='BreakoutDeterministic', version=4)\n",
            "EnvSpec(id='BreakoutNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'breakout', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='BreakoutNoFrameskip', version=4)\n",
            "EnvSpec(id='Breakout-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'breakout', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Breakout-ram', version=0)\n",
            "EnvSpec(id='Breakout-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'breakout', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Breakout-ramDeterministic', version=0)\n",
            "EnvSpec(id='Breakout-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'breakout', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Breakout-ramNoFrameskip', version=0)\n",
            "EnvSpec(id='Breakout-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'breakout', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Breakout-ram', version=4)\n",
            "EnvSpec(id='Breakout-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'breakout', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Breakout-ramDeterministic', version=4)\n",
            "EnvSpec(id='Breakout-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'breakout', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Breakout-ramNoFrameskip', version=4)\n",
            "EnvSpec(id='Carnival-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'carnival', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Carnival', version=0)\n",
            "EnvSpec(id='CarnivalDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'carnival', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='CarnivalDeterministic', version=0)\n",
            "EnvSpec(id='CarnivalNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'carnival', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='CarnivalNoFrameskip', version=0)\n",
            "EnvSpec(id='Carnival-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'carnival', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Carnival', version=4)\n",
            "EnvSpec(id='CarnivalDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'carnival', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='CarnivalDeterministic', version=4)\n",
            "EnvSpec(id='CarnivalNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'carnival', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='CarnivalNoFrameskip', version=4)\n",
            "EnvSpec(id='Carnival-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'carnival', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Carnival-ram', version=0)\n",
            "EnvSpec(id='Carnival-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'carnival', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Carnival-ramDeterministic', version=0)\n",
            "EnvSpec(id='Carnival-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'carnival', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Carnival-ramNoFrameskip', version=0)\n",
            "EnvSpec(id='Carnival-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'carnival', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Carnival-ram', version=4)\n",
            "EnvSpec(id='Carnival-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'carnival', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Carnival-ramDeterministic', version=4)\n",
            "EnvSpec(id='Carnival-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'carnival', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Carnival-ramNoFrameskip', version=4)\n",
            "EnvSpec(id='Centipede-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'centipede', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Centipede', version=0)\n",
            "EnvSpec(id='CentipedeDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'centipede', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='CentipedeDeterministic', version=0)\n",
            "EnvSpec(id='CentipedeNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'centipede', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='CentipedeNoFrameskip', version=0)\n",
            "EnvSpec(id='Centipede-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'centipede', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Centipede', version=4)\n",
            "EnvSpec(id='CentipedeDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'centipede', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='CentipedeDeterministic', version=4)\n",
            "EnvSpec(id='CentipedeNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'centipede', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='CentipedeNoFrameskip', version=4)\n",
            "EnvSpec(id='Centipede-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'centipede', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Centipede-ram', version=0)\n",
            "EnvSpec(id='Centipede-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'centipede', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Centipede-ramDeterministic', version=0)\n",
            "EnvSpec(id='Centipede-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'centipede', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Centipede-ramNoFrameskip', version=0)\n",
            "EnvSpec(id='Centipede-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'centipede', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Centipede-ram', version=4)\n",
            "EnvSpec(id='Centipede-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'centipede', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Centipede-ramDeterministic', version=4)\n",
            "EnvSpec(id='Centipede-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'centipede', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Centipede-ramNoFrameskip', version=4)\n",
            "EnvSpec(id='ChopperCommand-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'chopper_command', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='ChopperCommand', version=0)\n",
            "EnvSpec(id='ChopperCommandDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'chopper_command', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='ChopperCommandDeterministic', version=0)\n",
            "EnvSpec(id='ChopperCommandNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'chopper_command', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='ChopperCommandNoFrameskip', version=0)\n",
            "EnvSpec(id='ChopperCommand-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'chopper_command', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='ChopperCommand', version=4)\n",
            "EnvSpec(id='ChopperCommandDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'chopper_command', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='ChopperCommandDeterministic', version=4)\n",
            "EnvSpec(id='ChopperCommandNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'chopper_command', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='ChopperCommandNoFrameskip', version=4)\n",
            "EnvSpec(id='ChopperCommand-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'chopper_command', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='ChopperCommand-ram', version=0)\n",
            "EnvSpec(id='ChopperCommand-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'chopper_command', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='ChopperCommand-ramDeterministic', version=0)\n",
            "EnvSpec(id='ChopperCommand-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'chopper_command', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='ChopperCommand-ramNoFrameskip', version=0)\n",
            "EnvSpec(id='ChopperCommand-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'chopper_command', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='ChopperCommand-ram', version=4)\n",
            "EnvSpec(id='ChopperCommand-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'chopper_command', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='ChopperCommand-ramDeterministic', version=4)\n",
            "EnvSpec(id='ChopperCommand-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'chopper_command', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='ChopperCommand-ramNoFrameskip', version=4)\n",
            "EnvSpec(id='CrazyClimber-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'crazy_climber', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='CrazyClimber', version=0)\n",
            "EnvSpec(id='CrazyClimberDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'crazy_climber', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='CrazyClimberDeterministic', version=0)\n",
            "EnvSpec(id='CrazyClimberNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'crazy_climber', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='CrazyClimberNoFrameskip', version=0)\n",
            "EnvSpec(id='CrazyClimber-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'crazy_climber', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='CrazyClimber', version=4)\n",
            "EnvSpec(id='CrazyClimberDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'crazy_climber', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='CrazyClimberDeterministic', version=4)\n",
            "EnvSpec(id='CrazyClimberNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'crazy_climber', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='CrazyClimberNoFrameskip', version=4)\n",
            "EnvSpec(id='CrazyClimber-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'crazy_climber', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='CrazyClimber-ram', version=0)\n",
            "EnvSpec(id='CrazyClimber-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'crazy_climber', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='CrazyClimber-ramDeterministic', version=0)\n",
            "EnvSpec(id='CrazyClimber-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'crazy_climber', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='CrazyClimber-ramNoFrameskip', version=0)\n",
            "EnvSpec(id='CrazyClimber-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'crazy_climber', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='CrazyClimber-ram', version=4)\n",
            "EnvSpec(id='CrazyClimber-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'crazy_climber', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='CrazyClimber-ramDeterministic', version=4)\n",
            "EnvSpec(id='CrazyClimber-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'crazy_climber', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='CrazyClimber-ramNoFrameskip', version=4)\n",
            "EnvSpec(id='Defender-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'defender', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Defender', version=0)\n",
            "EnvSpec(id='DefenderDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'defender', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='DefenderDeterministic', version=0)\n",
            "EnvSpec(id='DefenderNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'defender', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='DefenderNoFrameskip', version=0)\n",
            "EnvSpec(id='Defender-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'defender', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Defender', version=4)\n",
            "EnvSpec(id='DefenderDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'defender', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='DefenderDeterministic', version=4)\n",
            "EnvSpec(id='DefenderNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'defender', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='DefenderNoFrameskip', version=4)\n",
            "EnvSpec(id='Defender-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'defender', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Defender-ram', version=0)\n",
            "EnvSpec(id='Defender-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'defender', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Defender-ramDeterministic', version=0)\n",
            "EnvSpec(id='Defender-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'defender', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Defender-ramNoFrameskip', version=0)\n",
            "EnvSpec(id='Defender-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'defender', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Defender-ram', version=4)\n",
            "EnvSpec(id='Defender-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'defender', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Defender-ramDeterministic', version=4)\n",
            "EnvSpec(id='Defender-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'defender', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Defender-ramNoFrameskip', version=4)\n",
            "EnvSpec(id='DemonAttack-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'demon_attack', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='DemonAttack', version=0)\n",
            "EnvSpec(id='DemonAttackDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'demon_attack', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='DemonAttackDeterministic', version=0)\n",
            "EnvSpec(id='DemonAttackNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'demon_attack', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='DemonAttackNoFrameskip', version=0)\n",
            "EnvSpec(id='DemonAttack-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'demon_attack', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='DemonAttack', version=4)\n",
            "EnvSpec(id='DemonAttackDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'demon_attack', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='DemonAttackDeterministic', version=4)\n",
            "EnvSpec(id='DemonAttackNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'demon_attack', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='DemonAttackNoFrameskip', version=4)\n",
            "EnvSpec(id='DemonAttack-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'demon_attack', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='DemonAttack-ram', version=0)\n",
            "EnvSpec(id='DemonAttack-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'demon_attack', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='DemonAttack-ramDeterministic', version=0)\n",
            "EnvSpec(id='DemonAttack-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'demon_attack', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='DemonAttack-ramNoFrameskip', version=0)\n",
            "EnvSpec(id='DemonAttack-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'demon_attack', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='DemonAttack-ram', version=4)\n",
            "EnvSpec(id='DemonAttack-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'demon_attack', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='DemonAttack-ramDeterministic', version=4)\n",
            "EnvSpec(id='DemonAttack-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'demon_attack', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='DemonAttack-ramNoFrameskip', version=4)\n",
            "EnvSpec(id='DoubleDunk-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'double_dunk', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='DoubleDunk', version=0)\n",
            "EnvSpec(id='DoubleDunkDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'double_dunk', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='DoubleDunkDeterministic', version=0)\n",
            "EnvSpec(id='DoubleDunkNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'double_dunk', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='DoubleDunkNoFrameskip', version=0)\n",
            "EnvSpec(id='DoubleDunk-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'double_dunk', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='DoubleDunk', version=4)\n",
            "EnvSpec(id='DoubleDunkDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'double_dunk', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='DoubleDunkDeterministic', version=4)\n",
            "EnvSpec(id='DoubleDunkNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'double_dunk', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='DoubleDunkNoFrameskip', version=4)\n",
            "EnvSpec(id='DoubleDunk-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'double_dunk', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='DoubleDunk-ram', version=0)\n",
            "EnvSpec(id='DoubleDunk-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'double_dunk', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='DoubleDunk-ramDeterministic', version=0)\n",
            "EnvSpec(id='DoubleDunk-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'double_dunk', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='DoubleDunk-ramNoFrameskip', version=0)\n",
            "EnvSpec(id='DoubleDunk-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'double_dunk', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='DoubleDunk-ram', version=4)\n",
            "EnvSpec(id='DoubleDunk-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'double_dunk', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='DoubleDunk-ramDeterministic', version=4)\n",
            "EnvSpec(id='DoubleDunk-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'double_dunk', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='DoubleDunk-ramNoFrameskip', version=4)\n",
            "EnvSpec(id='ElevatorAction-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'elevator_action', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='ElevatorAction', version=0)\n",
            "EnvSpec(id='ElevatorActionDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'elevator_action', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='ElevatorActionDeterministic', version=0)\n",
            "EnvSpec(id='ElevatorActionNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'elevator_action', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='ElevatorActionNoFrameskip', version=0)\n",
            "EnvSpec(id='ElevatorAction-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'elevator_action', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='ElevatorAction', version=4)\n",
            "EnvSpec(id='ElevatorActionDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'elevator_action', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='ElevatorActionDeterministic', version=4)\n",
            "EnvSpec(id='ElevatorActionNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'elevator_action', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='ElevatorActionNoFrameskip', version=4)\n",
            "EnvSpec(id='ElevatorAction-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'elevator_action', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='ElevatorAction-ram', version=0)\n",
            "EnvSpec(id='ElevatorAction-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'elevator_action', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='ElevatorAction-ramDeterministic', version=0)\n",
            "EnvSpec(id='ElevatorAction-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'elevator_action', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='ElevatorAction-ramNoFrameskip', version=0)\n",
            "EnvSpec(id='ElevatorAction-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'elevator_action', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='ElevatorAction-ram', version=4)\n",
            "EnvSpec(id='ElevatorAction-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'elevator_action', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='ElevatorAction-ramDeterministic', version=4)\n",
            "EnvSpec(id='ElevatorAction-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'elevator_action', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='ElevatorAction-ramNoFrameskip', version=4)\n",
            "EnvSpec(id='Enduro-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'enduro', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Enduro', version=0)\n",
            "EnvSpec(id='EnduroDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'enduro', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='EnduroDeterministic', version=0)\n",
            "EnvSpec(id='EnduroNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'enduro', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='EnduroNoFrameskip', version=0)\n",
            "EnvSpec(id='Enduro-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'enduro', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Enduro', version=4)\n",
            "EnvSpec(id='EnduroDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'enduro', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='EnduroDeterministic', version=4)\n",
            "EnvSpec(id='EnduroNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'enduro', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='EnduroNoFrameskip', version=4)\n",
            "EnvSpec(id='Enduro-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'enduro', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Enduro-ram', version=0)\n",
            "EnvSpec(id='Enduro-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'enduro', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Enduro-ramDeterministic', version=0)\n",
            "EnvSpec(id='Enduro-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'enduro', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Enduro-ramNoFrameskip', version=0)\n",
            "EnvSpec(id='Enduro-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'enduro', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Enduro-ram', version=4)\n",
            "EnvSpec(id='Enduro-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'enduro', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Enduro-ramDeterministic', version=4)\n",
            "EnvSpec(id='Enduro-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'enduro', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Enduro-ramNoFrameskip', version=4)\n",
            "EnvSpec(id='FishingDerby-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'fishing_derby', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='FishingDerby', version=0)\n",
            "EnvSpec(id='FishingDerbyDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'fishing_derby', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='FishingDerbyDeterministic', version=0)\n",
            "EnvSpec(id='FishingDerbyNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'fishing_derby', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='FishingDerbyNoFrameskip', version=0)\n",
            "EnvSpec(id='FishingDerby-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'fishing_derby', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='FishingDerby', version=4)\n",
            "EnvSpec(id='FishingDerbyDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'fishing_derby', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='FishingDerbyDeterministic', version=4)\n",
            "EnvSpec(id='FishingDerbyNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'fishing_derby', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='FishingDerbyNoFrameskip', version=4)\n",
            "EnvSpec(id='FishingDerby-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'fishing_derby', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='FishingDerby-ram', version=0)\n",
            "EnvSpec(id='FishingDerby-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'fishing_derby', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='FishingDerby-ramDeterministic', version=0)\n",
            "EnvSpec(id='FishingDerby-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'fishing_derby', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='FishingDerby-ramNoFrameskip', version=0)\n",
            "EnvSpec(id='FishingDerby-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'fishing_derby', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='FishingDerby-ram', version=4)\n",
            "EnvSpec(id='FishingDerby-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'fishing_derby', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='FishingDerby-ramDeterministic', version=4)\n",
            "EnvSpec(id='FishingDerby-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'fishing_derby', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='FishingDerby-ramNoFrameskip', version=4)\n",
            "EnvSpec(id='Freeway-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'freeway', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Freeway', version=0)\n",
            "EnvSpec(id='FreewayDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'freeway', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='FreewayDeterministic', version=0)\n",
            "EnvSpec(id='FreewayNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'freeway', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='FreewayNoFrameskip', version=0)\n",
            "EnvSpec(id='Freeway-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'freeway', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Freeway', version=4)\n",
            "EnvSpec(id='FreewayDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'freeway', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='FreewayDeterministic', version=4)\n",
            "EnvSpec(id='FreewayNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'freeway', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='FreewayNoFrameskip', version=4)\n",
            "EnvSpec(id='Freeway-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'freeway', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Freeway-ram', version=0)\n",
            "EnvSpec(id='Freeway-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'freeway', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Freeway-ramDeterministic', version=0)\n",
            "EnvSpec(id='Freeway-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'freeway', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Freeway-ramNoFrameskip', version=0)\n",
            "EnvSpec(id='Freeway-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'freeway', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Freeway-ram', version=4)\n",
            "EnvSpec(id='Freeway-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'freeway', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Freeway-ramDeterministic', version=4)\n",
            "EnvSpec(id='Freeway-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'freeway', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Freeway-ramNoFrameskip', version=4)\n",
            "EnvSpec(id='Frostbite-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'frostbite', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Frostbite', version=0)\n",
            "EnvSpec(id='FrostbiteDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'frostbite', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='FrostbiteDeterministic', version=0)\n",
            "EnvSpec(id='FrostbiteNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'frostbite', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='FrostbiteNoFrameskip', version=0)\n",
            "EnvSpec(id='Frostbite-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'frostbite', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Frostbite', version=4)\n",
            "EnvSpec(id='FrostbiteDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'frostbite', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='FrostbiteDeterministic', version=4)\n",
            "EnvSpec(id='FrostbiteNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'frostbite', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='FrostbiteNoFrameskip', version=4)\n",
            "EnvSpec(id='Frostbite-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'frostbite', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Frostbite-ram', version=0)\n",
            "EnvSpec(id='Frostbite-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'frostbite', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Frostbite-ramDeterministic', version=0)\n",
            "EnvSpec(id='Frostbite-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'frostbite', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Frostbite-ramNoFrameskip', version=0)\n",
            "EnvSpec(id='Frostbite-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'frostbite', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Frostbite-ram', version=4)\n",
            "EnvSpec(id='Frostbite-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'frostbite', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Frostbite-ramDeterministic', version=4)\n",
            "EnvSpec(id='Frostbite-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'frostbite', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Frostbite-ramNoFrameskip', version=4)\n",
            "EnvSpec(id='Gopher-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'gopher', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Gopher', version=0)\n",
            "EnvSpec(id='GopherDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'gopher', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='GopherDeterministic', version=0)\n",
            "EnvSpec(id='GopherNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'gopher', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='GopherNoFrameskip', version=0)\n",
            "EnvSpec(id='Gopher-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'gopher', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Gopher', version=4)\n",
            "EnvSpec(id='GopherDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'gopher', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='GopherDeterministic', version=4)\n",
            "EnvSpec(id='GopherNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'gopher', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='GopherNoFrameskip', version=4)\n",
            "EnvSpec(id='Gopher-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'gopher', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Gopher-ram', version=0)\n",
            "EnvSpec(id='Gopher-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'gopher', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Gopher-ramDeterministic', version=0)\n",
            "EnvSpec(id='Gopher-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'gopher', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Gopher-ramNoFrameskip', version=0)\n",
            "EnvSpec(id='Gopher-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'gopher', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Gopher-ram', version=4)\n",
            "EnvSpec(id='Gopher-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'gopher', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Gopher-ramDeterministic', version=4)\n",
            "EnvSpec(id='Gopher-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'gopher', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Gopher-ramNoFrameskip', version=4)\n",
            "EnvSpec(id='Gravitar-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'gravitar', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Gravitar', version=0)\n",
            "EnvSpec(id='GravitarDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'gravitar', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='GravitarDeterministic', version=0)\n",
            "EnvSpec(id='GravitarNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'gravitar', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='GravitarNoFrameskip', version=0)\n",
            "EnvSpec(id='Gravitar-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'gravitar', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Gravitar', version=4)\n",
            "EnvSpec(id='GravitarDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'gravitar', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='GravitarDeterministic', version=4)\n",
            "EnvSpec(id='GravitarNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'gravitar', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='GravitarNoFrameskip', version=4)\n",
            "EnvSpec(id='Gravitar-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'gravitar', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Gravitar-ram', version=0)\n",
            "EnvSpec(id='Gravitar-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'gravitar', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Gravitar-ramDeterministic', version=0)\n",
            "EnvSpec(id='Gravitar-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'gravitar', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Gravitar-ramNoFrameskip', version=0)\n",
            "EnvSpec(id='Gravitar-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'gravitar', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Gravitar-ram', version=4)\n",
            "EnvSpec(id='Gravitar-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'gravitar', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Gravitar-ramDeterministic', version=4)\n",
            "EnvSpec(id='Gravitar-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'gravitar', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Gravitar-ramNoFrameskip', version=4)\n",
            "EnvSpec(id='Hero-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'hero', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Hero', version=0)\n",
            "EnvSpec(id='HeroDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'hero', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='HeroDeterministic', version=0)\n",
            "EnvSpec(id='HeroNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'hero', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='HeroNoFrameskip', version=0)\n",
            "EnvSpec(id='Hero-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'hero', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Hero', version=4)\n",
            "EnvSpec(id='HeroDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'hero', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='HeroDeterministic', version=4)\n",
            "EnvSpec(id='HeroNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'hero', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='HeroNoFrameskip', version=4)\n",
            "EnvSpec(id='Hero-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'hero', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Hero-ram', version=0)\n",
            "EnvSpec(id='Hero-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'hero', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Hero-ramDeterministic', version=0)\n",
            "EnvSpec(id='Hero-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'hero', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Hero-ramNoFrameskip', version=0)\n",
            "EnvSpec(id='Hero-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'hero', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Hero-ram', version=4)\n",
            "EnvSpec(id='Hero-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'hero', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Hero-ramDeterministic', version=4)\n",
            "EnvSpec(id='Hero-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'hero', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Hero-ramNoFrameskip', version=4)\n",
            "EnvSpec(id='IceHockey-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'ice_hockey', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='IceHockey', version=0)\n",
            "EnvSpec(id='IceHockeyDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'ice_hockey', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='IceHockeyDeterministic', version=0)\n",
            "EnvSpec(id='IceHockeyNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'ice_hockey', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='IceHockeyNoFrameskip', version=0)\n",
            "EnvSpec(id='IceHockey-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'ice_hockey', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='IceHockey', version=4)\n",
            "EnvSpec(id='IceHockeyDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'ice_hockey', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='IceHockeyDeterministic', version=4)\n",
            "EnvSpec(id='IceHockeyNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'ice_hockey', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='IceHockeyNoFrameskip', version=4)\n",
            "EnvSpec(id='IceHockey-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'ice_hockey', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='IceHockey-ram', version=0)\n",
            "EnvSpec(id='IceHockey-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'ice_hockey', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='IceHockey-ramDeterministic', version=0)\n",
            "EnvSpec(id='IceHockey-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'ice_hockey', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='IceHockey-ramNoFrameskip', version=0)\n",
            "EnvSpec(id='IceHockey-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'ice_hockey', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='IceHockey-ram', version=4)\n",
            "EnvSpec(id='IceHockey-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'ice_hockey', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='IceHockey-ramDeterministic', version=4)\n",
            "EnvSpec(id='IceHockey-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'ice_hockey', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='IceHockey-ramNoFrameskip', version=4)\n",
            "EnvSpec(id='Jamesbond-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'jamesbond', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Jamesbond', version=0)\n",
            "EnvSpec(id='JamesbondDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'jamesbond', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='JamesbondDeterministic', version=0)\n",
            "EnvSpec(id='JamesbondNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'jamesbond', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='JamesbondNoFrameskip', version=0)\n",
            "EnvSpec(id='Jamesbond-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'jamesbond', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Jamesbond', version=4)\n",
            "EnvSpec(id='JamesbondDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'jamesbond', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='JamesbondDeterministic', version=4)\n",
            "EnvSpec(id='JamesbondNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'jamesbond', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='JamesbondNoFrameskip', version=4)\n",
            "EnvSpec(id='Jamesbond-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'jamesbond', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Jamesbond-ram', version=0)\n",
            "EnvSpec(id='Jamesbond-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'jamesbond', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Jamesbond-ramDeterministic', version=0)\n",
            "EnvSpec(id='Jamesbond-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'jamesbond', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Jamesbond-ramNoFrameskip', version=0)\n",
            "EnvSpec(id='Jamesbond-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'jamesbond', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Jamesbond-ram', version=4)\n",
            "EnvSpec(id='Jamesbond-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'jamesbond', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Jamesbond-ramDeterministic', version=4)\n",
            "EnvSpec(id='Jamesbond-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'jamesbond', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Jamesbond-ramNoFrameskip', version=4)\n",
            "EnvSpec(id='JourneyEscape-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'journey_escape', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='JourneyEscape', version=0)\n",
            "EnvSpec(id='JourneyEscapeDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'journey_escape', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='JourneyEscapeDeterministic', version=0)\n",
            "EnvSpec(id='JourneyEscapeNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'journey_escape', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='JourneyEscapeNoFrameskip', version=0)\n",
            "EnvSpec(id='JourneyEscape-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'journey_escape', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='JourneyEscape', version=4)\n",
            "EnvSpec(id='JourneyEscapeDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'journey_escape', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='JourneyEscapeDeterministic', version=4)\n",
            "EnvSpec(id='JourneyEscapeNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'journey_escape', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='JourneyEscapeNoFrameskip', version=4)\n",
            "EnvSpec(id='JourneyEscape-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'journey_escape', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='JourneyEscape-ram', version=0)\n",
            "EnvSpec(id='JourneyEscape-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'journey_escape', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='JourneyEscape-ramDeterministic', version=0)\n",
            "EnvSpec(id='JourneyEscape-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'journey_escape', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='JourneyEscape-ramNoFrameskip', version=0)\n",
            "EnvSpec(id='JourneyEscape-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'journey_escape', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='JourneyEscape-ram', version=4)\n",
            "EnvSpec(id='JourneyEscape-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'journey_escape', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='JourneyEscape-ramDeterministic', version=4)\n",
            "EnvSpec(id='JourneyEscape-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'journey_escape', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='JourneyEscape-ramNoFrameskip', version=4)\n",
            "EnvSpec(id='Kangaroo-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'kangaroo', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Kangaroo', version=0)\n",
            "EnvSpec(id='KangarooDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'kangaroo', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='KangarooDeterministic', version=0)\n",
            "EnvSpec(id='KangarooNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'kangaroo', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='KangarooNoFrameskip', version=0)\n",
            "EnvSpec(id='Kangaroo-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'kangaroo', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Kangaroo', version=4)\n",
            "EnvSpec(id='KangarooDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'kangaroo', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='KangarooDeterministic', version=4)\n",
            "EnvSpec(id='KangarooNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'kangaroo', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='KangarooNoFrameskip', version=4)\n",
            "EnvSpec(id='Kangaroo-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'kangaroo', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Kangaroo-ram', version=0)\n",
            "EnvSpec(id='Kangaroo-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'kangaroo', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Kangaroo-ramDeterministic', version=0)\n",
            "EnvSpec(id='Kangaroo-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'kangaroo', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Kangaroo-ramNoFrameskip', version=0)\n",
            "EnvSpec(id='Kangaroo-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'kangaroo', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Kangaroo-ram', version=4)\n",
            "EnvSpec(id='Kangaroo-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'kangaroo', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Kangaroo-ramDeterministic', version=4)\n",
            "EnvSpec(id='Kangaroo-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'kangaroo', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Kangaroo-ramNoFrameskip', version=4)\n",
            "EnvSpec(id='Krull-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'krull', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Krull', version=0)\n",
            "EnvSpec(id='KrullDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'krull', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='KrullDeterministic', version=0)\n",
            "EnvSpec(id='KrullNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'krull', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='KrullNoFrameskip', version=0)\n",
            "EnvSpec(id='Krull-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'krull', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Krull', version=4)\n",
            "EnvSpec(id='KrullDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'krull', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='KrullDeterministic', version=4)\n",
            "EnvSpec(id='KrullNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'krull', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='KrullNoFrameskip', version=4)\n",
            "EnvSpec(id='Krull-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'krull', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Krull-ram', version=0)\n",
            "EnvSpec(id='Krull-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'krull', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Krull-ramDeterministic', version=0)\n",
            "EnvSpec(id='Krull-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'krull', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Krull-ramNoFrameskip', version=0)\n",
            "EnvSpec(id='Krull-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'krull', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Krull-ram', version=4)\n",
            "EnvSpec(id='Krull-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'krull', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Krull-ramDeterministic', version=4)\n",
            "EnvSpec(id='Krull-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'krull', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Krull-ramNoFrameskip', version=4)\n",
            "EnvSpec(id='KungFuMaster-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'kung_fu_master', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='KungFuMaster', version=0)\n",
            "EnvSpec(id='KungFuMasterDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'kung_fu_master', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='KungFuMasterDeterministic', version=0)\n",
            "EnvSpec(id='KungFuMasterNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'kung_fu_master', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='KungFuMasterNoFrameskip', version=0)\n",
            "EnvSpec(id='KungFuMaster-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'kung_fu_master', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='KungFuMaster', version=4)\n",
            "EnvSpec(id='KungFuMasterDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'kung_fu_master', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='KungFuMasterDeterministic', version=4)\n",
            "EnvSpec(id='KungFuMasterNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'kung_fu_master', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='KungFuMasterNoFrameskip', version=4)\n",
            "EnvSpec(id='KungFuMaster-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'kung_fu_master', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='KungFuMaster-ram', version=0)\n",
            "EnvSpec(id='KungFuMaster-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'kung_fu_master', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='KungFuMaster-ramDeterministic', version=0)\n",
            "EnvSpec(id='KungFuMaster-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'kung_fu_master', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='KungFuMaster-ramNoFrameskip', version=0)\n",
            "EnvSpec(id='KungFuMaster-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'kung_fu_master', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='KungFuMaster-ram', version=4)\n",
            "EnvSpec(id='KungFuMaster-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'kung_fu_master', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='KungFuMaster-ramDeterministic', version=4)\n",
            "EnvSpec(id='KungFuMaster-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'kung_fu_master', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='KungFuMaster-ramNoFrameskip', version=4)\n",
            "EnvSpec(id='MontezumaRevenge-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'montezuma_revenge', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='MontezumaRevenge', version=0)\n",
            "EnvSpec(id='MontezumaRevengeDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'montezuma_revenge', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='MontezumaRevengeDeterministic', version=0)\n",
            "EnvSpec(id='MontezumaRevengeNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'montezuma_revenge', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='MontezumaRevengeNoFrameskip', version=0)\n",
            "EnvSpec(id='MontezumaRevenge-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'montezuma_revenge', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='MontezumaRevenge', version=4)\n",
            "EnvSpec(id='MontezumaRevengeDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'montezuma_revenge', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='MontezumaRevengeDeterministic', version=4)\n",
            "EnvSpec(id='MontezumaRevengeNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'montezuma_revenge', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='MontezumaRevengeNoFrameskip', version=4)\n",
            "EnvSpec(id='MontezumaRevenge-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'montezuma_revenge', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='MontezumaRevenge-ram', version=0)\n",
            "EnvSpec(id='MontezumaRevenge-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'montezuma_revenge', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='MontezumaRevenge-ramDeterministic', version=0)\n",
            "EnvSpec(id='MontezumaRevenge-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'montezuma_revenge', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='MontezumaRevenge-ramNoFrameskip', version=0)\n",
            "EnvSpec(id='MontezumaRevenge-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'montezuma_revenge', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='MontezumaRevenge-ram', version=4)\n",
            "EnvSpec(id='MontezumaRevenge-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'montezuma_revenge', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='MontezumaRevenge-ramDeterministic', version=4)\n",
            "EnvSpec(id='MontezumaRevenge-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'montezuma_revenge', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='MontezumaRevenge-ramNoFrameskip', version=4)\n",
            "EnvSpec(id='MsPacman-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'ms_pacman', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='MsPacman', version=0)\n",
            "EnvSpec(id='MsPacmanDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'ms_pacman', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='MsPacmanDeterministic', version=0)\n",
            "EnvSpec(id='MsPacmanNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'ms_pacman', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='MsPacmanNoFrameskip', version=0)\n",
            "EnvSpec(id='MsPacman-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'ms_pacman', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='MsPacman', version=4)\n",
            "EnvSpec(id='MsPacmanDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'ms_pacman', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='MsPacmanDeterministic', version=4)\n",
            "EnvSpec(id='MsPacmanNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'ms_pacman', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='MsPacmanNoFrameskip', version=4)\n",
            "EnvSpec(id='MsPacman-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'ms_pacman', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='MsPacman-ram', version=0)\n",
            "EnvSpec(id='MsPacman-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'ms_pacman', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='MsPacman-ramDeterministic', version=0)\n",
            "EnvSpec(id='MsPacman-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'ms_pacman', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='MsPacman-ramNoFrameskip', version=0)\n",
            "EnvSpec(id='MsPacman-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'ms_pacman', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='MsPacman-ram', version=4)\n",
            "EnvSpec(id='MsPacman-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'ms_pacman', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='MsPacman-ramDeterministic', version=4)\n",
            "EnvSpec(id='MsPacman-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'ms_pacman', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='MsPacman-ramNoFrameskip', version=4)\n",
            "EnvSpec(id='NameThisGame-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'name_this_game', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='NameThisGame', version=0)\n",
            "EnvSpec(id='NameThisGameDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'name_this_game', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='NameThisGameDeterministic', version=0)\n",
            "EnvSpec(id='NameThisGameNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'name_this_game', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='NameThisGameNoFrameskip', version=0)\n",
            "EnvSpec(id='NameThisGame-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'name_this_game', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='NameThisGame', version=4)\n",
            "EnvSpec(id='NameThisGameDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'name_this_game', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='NameThisGameDeterministic', version=4)\n",
            "EnvSpec(id='NameThisGameNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'name_this_game', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='NameThisGameNoFrameskip', version=4)\n",
            "EnvSpec(id='NameThisGame-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'name_this_game', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='NameThisGame-ram', version=0)\n",
            "EnvSpec(id='NameThisGame-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'name_this_game', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='NameThisGame-ramDeterministic', version=0)\n",
            "EnvSpec(id='NameThisGame-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'name_this_game', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='NameThisGame-ramNoFrameskip', version=0)\n",
            "EnvSpec(id='NameThisGame-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'name_this_game', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='NameThisGame-ram', version=4)\n",
            "EnvSpec(id='NameThisGame-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'name_this_game', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='NameThisGame-ramDeterministic', version=4)\n",
            "EnvSpec(id='NameThisGame-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'name_this_game', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='NameThisGame-ramNoFrameskip', version=4)\n",
            "EnvSpec(id='Phoenix-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'phoenix', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Phoenix', version=0)\n",
            "EnvSpec(id='PhoenixDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'phoenix', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='PhoenixDeterministic', version=0)\n",
            "EnvSpec(id='PhoenixNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'phoenix', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='PhoenixNoFrameskip', version=0)\n",
            "EnvSpec(id='Phoenix-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'phoenix', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Phoenix', version=4)\n",
            "EnvSpec(id='PhoenixDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'phoenix', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='PhoenixDeterministic', version=4)\n",
            "EnvSpec(id='PhoenixNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'phoenix', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='PhoenixNoFrameskip', version=4)\n",
            "EnvSpec(id='Phoenix-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'phoenix', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Phoenix-ram', version=0)\n",
            "EnvSpec(id='Phoenix-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'phoenix', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Phoenix-ramDeterministic', version=0)\n",
            "EnvSpec(id='Phoenix-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'phoenix', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Phoenix-ramNoFrameskip', version=0)\n",
            "EnvSpec(id='Phoenix-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'phoenix', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Phoenix-ram', version=4)\n",
            "EnvSpec(id='Phoenix-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'phoenix', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Phoenix-ramDeterministic', version=4)\n",
            "EnvSpec(id='Phoenix-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'phoenix', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Phoenix-ramNoFrameskip', version=4)\n",
            "EnvSpec(id='Pitfall-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pitfall', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Pitfall', version=0)\n",
            "EnvSpec(id='PitfallDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pitfall', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='PitfallDeterministic', version=0)\n",
            "EnvSpec(id='PitfallNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pitfall', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='PitfallNoFrameskip', version=0)\n",
            "EnvSpec(id='Pitfall-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pitfall', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Pitfall', version=4)\n",
            "EnvSpec(id='PitfallDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pitfall', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='PitfallDeterministic', version=4)\n",
            "EnvSpec(id='PitfallNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pitfall', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='PitfallNoFrameskip', version=4)\n",
            "EnvSpec(id='Pitfall-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pitfall', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Pitfall-ram', version=0)\n",
            "EnvSpec(id='Pitfall-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pitfall', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Pitfall-ramDeterministic', version=0)\n",
            "EnvSpec(id='Pitfall-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pitfall', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Pitfall-ramNoFrameskip', version=0)\n",
            "EnvSpec(id='Pitfall-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pitfall', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Pitfall-ram', version=4)\n",
            "EnvSpec(id='Pitfall-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pitfall', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Pitfall-ramDeterministic', version=4)\n",
            "EnvSpec(id='Pitfall-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pitfall', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Pitfall-ramNoFrameskip', version=4)\n",
            "EnvSpec(id='Pong-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pong', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Pong', version=0)\n",
            "EnvSpec(id='PongDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pong', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='PongDeterministic', version=0)\n",
            "EnvSpec(id='PongNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pong', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='PongNoFrameskip', version=0)\n",
            "EnvSpec(id='Pong-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pong', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Pong', version=4)\n",
            "EnvSpec(id='PongDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pong', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='PongDeterministic', version=4)\n",
            "EnvSpec(id='PongNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pong', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='PongNoFrameskip', version=4)\n",
            "EnvSpec(id='Pong-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pong', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Pong-ram', version=0)\n",
            "EnvSpec(id='Pong-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pong', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Pong-ramDeterministic', version=0)\n",
            "EnvSpec(id='Pong-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pong', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Pong-ramNoFrameskip', version=0)\n",
            "EnvSpec(id='Pong-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pong', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Pong-ram', version=4)\n",
            "EnvSpec(id='Pong-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pong', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Pong-ramDeterministic', version=4)\n",
            "EnvSpec(id='Pong-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pong', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Pong-ramNoFrameskip', version=4)\n",
            "EnvSpec(id='Pooyan-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pooyan', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Pooyan', version=0)\n",
            "EnvSpec(id='PooyanDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pooyan', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='PooyanDeterministic', version=0)\n",
            "EnvSpec(id='PooyanNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pooyan', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='PooyanNoFrameskip', version=0)\n",
            "EnvSpec(id='Pooyan-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pooyan', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Pooyan', version=4)\n",
            "EnvSpec(id='PooyanDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pooyan', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='PooyanDeterministic', version=4)\n",
            "EnvSpec(id='PooyanNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pooyan', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='PooyanNoFrameskip', version=4)\n",
            "EnvSpec(id='Pooyan-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pooyan', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Pooyan-ram', version=0)\n",
            "EnvSpec(id='Pooyan-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pooyan', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Pooyan-ramDeterministic', version=0)\n",
            "EnvSpec(id='Pooyan-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pooyan', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Pooyan-ramNoFrameskip', version=0)\n",
            "EnvSpec(id='Pooyan-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pooyan', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Pooyan-ram', version=4)\n",
            "EnvSpec(id='Pooyan-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pooyan', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Pooyan-ramDeterministic', version=4)\n",
            "EnvSpec(id='Pooyan-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pooyan', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Pooyan-ramNoFrameskip', version=4)\n",
            "EnvSpec(id='PrivateEye-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'private_eye', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='PrivateEye', version=0)\n",
            "EnvSpec(id='PrivateEyeDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'private_eye', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='PrivateEyeDeterministic', version=0)\n",
            "EnvSpec(id='PrivateEyeNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'private_eye', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='PrivateEyeNoFrameskip', version=0)\n",
            "EnvSpec(id='PrivateEye-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'private_eye', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='PrivateEye', version=4)\n",
            "EnvSpec(id='PrivateEyeDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'private_eye', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='PrivateEyeDeterministic', version=4)\n",
            "EnvSpec(id='PrivateEyeNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'private_eye', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='PrivateEyeNoFrameskip', version=4)\n",
            "EnvSpec(id='PrivateEye-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'private_eye', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='PrivateEye-ram', version=0)\n",
            "EnvSpec(id='PrivateEye-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'private_eye', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='PrivateEye-ramDeterministic', version=0)\n",
            "EnvSpec(id='PrivateEye-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'private_eye', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='PrivateEye-ramNoFrameskip', version=0)\n",
            "EnvSpec(id='PrivateEye-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'private_eye', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='PrivateEye-ram', version=4)\n",
            "EnvSpec(id='PrivateEye-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'private_eye', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='PrivateEye-ramDeterministic', version=4)\n",
            "EnvSpec(id='PrivateEye-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'private_eye', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='PrivateEye-ramNoFrameskip', version=4)\n",
            "EnvSpec(id='Qbert-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'qbert', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Qbert', version=0)\n",
            "EnvSpec(id='QbertDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'qbert', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='QbertDeterministic', version=0)\n",
            "EnvSpec(id='QbertNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'qbert', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='QbertNoFrameskip', version=0)\n",
            "EnvSpec(id='Qbert-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'qbert', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Qbert', version=4)\n",
            "EnvSpec(id='QbertDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'qbert', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='QbertDeterministic', version=4)\n",
            "EnvSpec(id='QbertNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'qbert', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='QbertNoFrameskip', version=4)\n",
            "EnvSpec(id='Qbert-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'qbert', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Qbert-ram', version=0)\n",
            "EnvSpec(id='Qbert-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'qbert', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Qbert-ramDeterministic', version=0)\n",
            "EnvSpec(id='Qbert-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'qbert', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Qbert-ramNoFrameskip', version=0)\n",
            "EnvSpec(id='Qbert-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'qbert', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Qbert-ram', version=4)\n",
            "EnvSpec(id='Qbert-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'qbert', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Qbert-ramDeterministic', version=4)\n",
            "EnvSpec(id='Qbert-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'qbert', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Qbert-ramNoFrameskip', version=4)\n",
            "EnvSpec(id='Riverraid-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'riverraid', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Riverraid', version=0)\n",
            "EnvSpec(id='RiverraidDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'riverraid', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='RiverraidDeterministic', version=0)\n",
            "EnvSpec(id='RiverraidNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'riverraid', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='RiverraidNoFrameskip', version=0)\n",
            "EnvSpec(id='Riverraid-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'riverraid', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Riverraid', version=4)\n",
            "EnvSpec(id='RiverraidDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'riverraid', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='RiverraidDeterministic', version=4)\n",
            "EnvSpec(id='RiverraidNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'riverraid', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='RiverraidNoFrameskip', version=4)\n",
            "EnvSpec(id='Riverraid-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'riverraid', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Riverraid-ram', version=0)\n",
            "EnvSpec(id='Riverraid-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'riverraid', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Riverraid-ramDeterministic', version=0)\n",
            "EnvSpec(id='Riverraid-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'riverraid', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Riverraid-ramNoFrameskip', version=0)\n",
            "EnvSpec(id='Riverraid-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'riverraid', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Riverraid-ram', version=4)\n",
            "EnvSpec(id='Riverraid-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'riverraid', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Riverraid-ramDeterministic', version=4)\n",
            "EnvSpec(id='Riverraid-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'riverraid', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Riverraid-ramNoFrameskip', version=4)\n",
            "EnvSpec(id='RoadRunner-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'road_runner', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='RoadRunner', version=0)\n",
            "EnvSpec(id='RoadRunnerDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'road_runner', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='RoadRunnerDeterministic', version=0)\n",
            "EnvSpec(id='RoadRunnerNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'road_runner', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='RoadRunnerNoFrameskip', version=0)\n",
            "EnvSpec(id='RoadRunner-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'road_runner', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='RoadRunner', version=4)\n",
            "EnvSpec(id='RoadRunnerDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'road_runner', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='RoadRunnerDeterministic', version=4)\n",
            "EnvSpec(id='RoadRunnerNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'road_runner', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='RoadRunnerNoFrameskip', version=4)\n",
            "EnvSpec(id='RoadRunner-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'road_runner', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='RoadRunner-ram', version=0)\n",
            "EnvSpec(id='RoadRunner-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'road_runner', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='RoadRunner-ramDeterministic', version=0)\n",
            "EnvSpec(id='RoadRunner-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'road_runner', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='RoadRunner-ramNoFrameskip', version=0)\n",
            "EnvSpec(id='RoadRunner-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'road_runner', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='RoadRunner-ram', version=4)\n",
            "EnvSpec(id='RoadRunner-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'road_runner', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='RoadRunner-ramDeterministic', version=4)\n",
            "EnvSpec(id='RoadRunner-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'road_runner', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='RoadRunner-ramNoFrameskip', version=4)\n",
            "EnvSpec(id='Robotank-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'robotank', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Robotank', version=0)\n",
            "EnvSpec(id='RobotankDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'robotank', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='RobotankDeterministic', version=0)\n",
            "EnvSpec(id='RobotankNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'robotank', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='RobotankNoFrameskip', version=0)\n",
            "EnvSpec(id='Robotank-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'robotank', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Robotank', version=4)\n",
            "EnvSpec(id='RobotankDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'robotank', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='RobotankDeterministic', version=4)\n",
            "EnvSpec(id='RobotankNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'robotank', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='RobotankNoFrameskip', version=4)\n",
            "EnvSpec(id='Robotank-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'robotank', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Robotank-ram', version=0)\n",
            "EnvSpec(id='Robotank-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'robotank', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Robotank-ramDeterministic', version=0)\n",
            "EnvSpec(id='Robotank-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'robotank', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Robotank-ramNoFrameskip', version=0)\n",
            "EnvSpec(id='Robotank-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'robotank', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Robotank-ram', version=4)\n",
            "EnvSpec(id='Robotank-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'robotank', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Robotank-ramDeterministic', version=4)\n",
            "EnvSpec(id='Robotank-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'robotank', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Robotank-ramNoFrameskip', version=4)\n",
            "EnvSpec(id='Seaquest-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'seaquest', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Seaquest', version=0)\n",
            "EnvSpec(id='SeaquestDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'seaquest', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='SeaquestDeterministic', version=0)\n",
            "EnvSpec(id='SeaquestNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'seaquest', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='SeaquestNoFrameskip', version=0)\n",
            "EnvSpec(id='Seaquest-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'seaquest', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Seaquest', version=4)\n",
            "EnvSpec(id='SeaquestDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'seaquest', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='SeaquestDeterministic', version=4)\n",
            "EnvSpec(id='SeaquestNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'seaquest', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='SeaquestNoFrameskip', version=4)\n",
            "EnvSpec(id='Seaquest-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'seaquest', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Seaquest-ram', version=0)\n",
            "EnvSpec(id='Seaquest-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'seaquest', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Seaquest-ramDeterministic', version=0)\n",
            "EnvSpec(id='Seaquest-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'seaquest', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Seaquest-ramNoFrameskip', version=0)\n",
            "EnvSpec(id='Seaquest-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'seaquest', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Seaquest-ram', version=4)\n",
            "EnvSpec(id='Seaquest-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'seaquest', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Seaquest-ramDeterministic', version=4)\n",
            "EnvSpec(id='Seaquest-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'seaquest', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Seaquest-ramNoFrameskip', version=4)\n",
            "EnvSpec(id='Skiing-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'skiing', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Skiing', version=0)\n",
            "EnvSpec(id='SkiingDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'skiing', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='SkiingDeterministic', version=0)\n",
            "EnvSpec(id='SkiingNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'skiing', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='SkiingNoFrameskip', version=0)\n",
            "EnvSpec(id='Skiing-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'skiing', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Skiing', version=4)\n",
            "EnvSpec(id='SkiingDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'skiing', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='SkiingDeterministic', version=4)\n",
            "EnvSpec(id='SkiingNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'skiing', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='SkiingNoFrameskip', version=4)\n",
            "EnvSpec(id='Skiing-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'skiing', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Skiing-ram', version=0)\n",
            "EnvSpec(id='Skiing-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'skiing', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Skiing-ramDeterministic', version=0)\n",
            "EnvSpec(id='Skiing-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'skiing', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Skiing-ramNoFrameskip', version=0)\n",
            "EnvSpec(id='Skiing-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'skiing', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Skiing-ram', version=4)\n",
            "EnvSpec(id='Skiing-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'skiing', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Skiing-ramDeterministic', version=4)\n",
            "EnvSpec(id='Skiing-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'skiing', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Skiing-ramNoFrameskip', version=4)\n",
            "EnvSpec(id='Solaris-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'solaris', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Solaris', version=0)\n",
            "EnvSpec(id='SolarisDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'solaris', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='SolarisDeterministic', version=0)\n",
            "EnvSpec(id='SolarisNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'solaris', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='SolarisNoFrameskip', version=0)\n",
            "EnvSpec(id='Solaris-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'solaris', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Solaris', version=4)\n",
            "EnvSpec(id='SolarisDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'solaris', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='SolarisDeterministic', version=4)\n",
            "EnvSpec(id='SolarisNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'solaris', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='SolarisNoFrameskip', version=4)\n",
            "EnvSpec(id='Solaris-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'solaris', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Solaris-ram', version=0)\n",
            "EnvSpec(id='Solaris-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'solaris', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Solaris-ramDeterministic', version=0)\n",
            "EnvSpec(id='Solaris-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'solaris', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Solaris-ramNoFrameskip', version=0)\n",
            "EnvSpec(id='Solaris-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'solaris', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Solaris-ram', version=4)\n",
            "EnvSpec(id='Solaris-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'solaris', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Solaris-ramDeterministic', version=4)\n",
            "EnvSpec(id='Solaris-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'solaris', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Solaris-ramNoFrameskip', version=4)\n",
            "EnvSpec(id='SpaceInvaders-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'space_invaders', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='SpaceInvaders', version=0)\n",
            "EnvSpec(id='SpaceInvadersDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'space_invaders', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 3}, namespace=None, name='SpaceInvadersDeterministic', version=0)\n",
            "EnvSpec(id='SpaceInvadersNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=300000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'space_invaders', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='SpaceInvadersNoFrameskip', version=0)\n",
            "EnvSpec(id='SpaceInvaders-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'space_invaders', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='SpaceInvaders', version=4)\n",
            "EnvSpec(id='SpaceInvadersDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'space_invaders', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 3}, namespace=None, name='SpaceInvadersDeterministic', version=4)\n",
            "EnvSpec(id='SpaceInvadersNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=300000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'space_invaders', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='SpaceInvadersNoFrameskip', version=4)\n",
            "EnvSpec(id='SpaceInvaders-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'space_invaders', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='SpaceInvaders-ram', version=0)\n",
            "EnvSpec(id='SpaceInvaders-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'space_invaders', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 3}, namespace=None, name='SpaceInvaders-ramDeterministic', version=0)\n",
            "EnvSpec(id='SpaceInvaders-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=300000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'space_invaders', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='SpaceInvaders-ramNoFrameskip', version=0)\n",
            "EnvSpec(id='SpaceInvaders-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'space_invaders', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='SpaceInvaders-ram', version=4)\n",
            "EnvSpec(id='SpaceInvaders-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'space_invaders', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 3}, namespace=None, name='SpaceInvaders-ramDeterministic', version=4)\n",
            "EnvSpec(id='SpaceInvaders-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=300000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'space_invaders', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='SpaceInvaders-ramNoFrameskip', version=4)\n",
            "EnvSpec(id='StarGunner-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'star_gunner', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='StarGunner', version=0)\n",
            "EnvSpec(id='StarGunnerDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'star_gunner', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='StarGunnerDeterministic', version=0)\n",
            "EnvSpec(id='StarGunnerNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'star_gunner', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='StarGunnerNoFrameskip', version=0)\n",
            "EnvSpec(id='StarGunner-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'star_gunner', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='StarGunner', version=4)\n",
            "EnvSpec(id='StarGunnerDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'star_gunner', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='StarGunnerDeterministic', version=4)\n",
            "EnvSpec(id='StarGunnerNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'star_gunner', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='StarGunnerNoFrameskip', version=4)\n",
            "EnvSpec(id='StarGunner-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'star_gunner', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='StarGunner-ram', version=0)\n",
            "EnvSpec(id='StarGunner-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'star_gunner', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='StarGunner-ramDeterministic', version=0)\n",
            "EnvSpec(id='StarGunner-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'star_gunner', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='StarGunner-ramNoFrameskip', version=0)\n",
            "EnvSpec(id='StarGunner-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'star_gunner', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='StarGunner-ram', version=4)\n",
            "EnvSpec(id='StarGunner-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'star_gunner', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='StarGunner-ramDeterministic', version=4)\n",
            "EnvSpec(id='StarGunner-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'star_gunner', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='StarGunner-ramNoFrameskip', version=4)\n",
            "EnvSpec(id='Tennis-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'tennis', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Tennis', version=0)\n",
            "EnvSpec(id='TennisDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'tennis', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='TennisDeterministic', version=0)\n",
            "EnvSpec(id='TennisNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'tennis', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='TennisNoFrameskip', version=0)\n",
            "EnvSpec(id='Tennis-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'tennis', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Tennis', version=4)\n",
            "EnvSpec(id='TennisDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'tennis', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='TennisDeterministic', version=4)\n",
            "EnvSpec(id='TennisNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'tennis', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='TennisNoFrameskip', version=4)\n",
            "EnvSpec(id='Tennis-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'tennis', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Tennis-ram', version=0)\n",
            "EnvSpec(id='Tennis-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'tennis', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Tennis-ramDeterministic', version=0)\n",
            "EnvSpec(id='Tennis-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'tennis', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Tennis-ramNoFrameskip', version=0)\n",
            "EnvSpec(id='Tennis-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'tennis', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Tennis-ram', version=4)\n",
            "EnvSpec(id='Tennis-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'tennis', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Tennis-ramDeterministic', version=4)\n",
            "EnvSpec(id='Tennis-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'tennis', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Tennis-ramNoFrameskip', version=4)\n",
            "EnvSpec(id='TimePilot-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'time_pilot', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='TimePilot', version=0)\n",
            "EnvSpec(id='TimePilotDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'time_pilot', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='TimePilotDeterministic', version=0)\n",
            "EnvSpec(id='TimePilotNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'time_pilot', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='TimePilotNoFrameskip', version=0)\n",
            "EnvSpec(id='TimePilot-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'time_pilot', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='TimePilot', version=4)\n",
            "EnvSpec(id='TimePilotDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'time_pilot', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='TimePilotDeterministic', version=4)\n",
            "EnvSpec(id='TimePilotNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'time_pilot', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='TimePilotNoFrameskip', version=4)\n",
            "EnvSpec(id='TimePilot-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'time_pilot', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='TimePilot-ram', version=0)\n",
            "EnvSpec(id='TimePilot-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'time_pilot', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='TimePilot-ramDeterministic', version=0)\n",
            "EnvSpec(id='TimePilot-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'time_pilot', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='TimePilot-ramNoFrameskip', version=0)\n",
            "EnvSpec(id='TimePilot-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'time_pilot', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='TimePilot-ram', version=4)\n",
            "EnvSpec(id='TimePilot-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'time_pilot', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='TimePilot-ramDeterministic', version=4)\n",
            "EnvSpec(id='TimePilot-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'time_pilot', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='TimePilot-ramNoFrameskip', version=4)\n",
            "EnvSpec(id='Tutankham-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'tutankham', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Tutankham', version=0)\n",
            "EnvSpec(id='TutankhamDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'tutankham', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='TutankhamDeterministic', version=0)\n",
            "EnvSpec(id='TutankhamNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'tutankham', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='TutankhamNoFrameskip', version=0)\n",
            "EnvSpec(id='Tutankham-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'tutankham', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Tutankham', version=4)\n",
            "EnvSpec(id='TutankhamDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'tutankham', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='TutankhamDeterministic', version=4)\n",
            "EnvSpec(id='TutankhamNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'tutankham', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='TutankhamNoFrameskip', version=4)\n",
            "EnvSpec(id='Tutankham-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'tutankham', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Tutankham-ram', version=0)\n",
            "EnvSpec(id='Tutankham-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'tutankham', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Tutankham-ramDeterministic', version=0)\n",
            "EnvSpec(id='Tutankham-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'tutankham', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Tutankham-ramNoFrameskip', version=0)\n",
            "EnvSpec(id='Tutankham-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'tutankham', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Tutankham-ram', version=4)\n",
            "EnvSpec(id='Tutankham-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'tutankham', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Tutankham-ramDeterministic', version=4)\n",
            "EnvSpec(id='Tutankham-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'tutankham', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Tutankham-ramNoFrameskip', version=4)\n",
            "EnvSpec(id='UpNDown-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'up_n_down', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='UpNDown', version=0)\n",
            "EnvSpec(id='UpNDownDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'up_n_down', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='UpNDownDeterministic', version=0)\n",
            "EnvSpec(id='UpNDownNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'up_n_down', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='UpNDownNoFrameskip', version=0)\n",
            "EnvSpec(id='UpNDown-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'up_n_down', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='UpNDown', version=4)\n",
            "EnvSpec(id='UpNDownDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'up_n_down', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='UpNDownDeterministic', version=4)\n",
            "EnvSpec(id='UpNDownNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'up_n_down', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='UpNDownNoFrameskip', version=4)\n",
            "EnvSpec(id='UpNDown-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'up_n_down', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='UpNDown-ram', version=0)\n",
            "EnvSpec(id='UpNDown-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'up_n_down', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='UpNDown-ramDeterministic', version=0)\n",
            "EnvSpec(id='UpNDown-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'up_n_down', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='UpNDown-ramNoFrameskip', version=0)\n",
            "EnvSpec(id='UpNDown-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'up_n_down', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='UpNDown-ram', version=4)\n",
            "EnvSpec(id='UpNDown-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'up_n_down', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='UpNDown-ramDeterministic', version=4)\n",
            "EnvSpec(id='UpNDown-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'up_n_down', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='UpNDown-ramNoFrameskip', version=4)\n",
            "EnvSpec(id='Venture-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'venture', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Venture', version=0)\n",
            "EnvSpec(id='VentureDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'venture', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='VentureDeterministic', version=0)\n",
            "EnvSpec(id='VentureNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'venture', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='VentureNoFrameskip', version=0)\n",
            "EnvSpec(id='Venture-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'venture', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Venture', version=4)\n",
            "EnvSpec(id='VentureDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'venture', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='VentureDeterministic', version=4)\n",
            "EnvSpec(id='VentureNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'venture', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='VentureNoFrameskip', version=4)\n",
            "EnvSpec(id='Venture-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'venture', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Venture-ram', version=0)\n",
            "EnvSpec(id='Venture-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'venture', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Venture-ramDeterministic', version=0)\n",
            "EnvSpec(id='Venture-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'venture', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Venture-ramNoFrameskip', version=0)\n",
            "EnvSpec(id='Venture-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'venture', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Venture-ram', version=4)\n",
            "EnvSpec(id='Venture-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'venture', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Venture-ramDeterministic', version=4)\n",
            "EnvSpec(id='Venture-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'venture', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Venture-ramNoFrameskip', version=4)\n",
            "EnvSpec(id='VideoPinball-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'video_pinball', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='VideoPinball', version=0)\n",
            "EnvSpec(id='VideoPinballDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'video_pinball', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='VideoPinballDeterministic', version=0)\n",
            "EnvSpec(id='VideoPinballNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'video_pinball', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='VideoPinballNoFrameskip', version=0)\n",
            "EnvSpec(id='VideoPinball-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'video_pinball', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='VideoPinball', version=4)\n",
            "EnvSpec(id='VideoPinballDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'video_pinball', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='VideoPinballDeterministic', version=4)\n",
            "EnvSpec(id='VideoPinballNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'video_pinball', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='VideoPinballNoFrameskip', version=4)\n",
            "EnvSpec(id='VideoPinball-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'video_pinball', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='VideoPinball-ram', version=0)\n",
            "EnvSpec(id='VideoPinball-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'video_pinball', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='VideoPinball-ramDeterministic', version=0)\n",
            "EnvSpec(id='VideoPinball-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'video_pinball', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='VideoPinball-ramNoFrameskip', version=0)\n",
            "EnvSpec(id='VideoPinball-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'video_pinball', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='VideoPinball-ram', version=4)\n",
            "EnvSpec(id='VideoPinball-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'video_pinball', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='VideoPinball-ramDeterministic', version=4)\n",
            "EnvSpec(id='VideoPinball-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'video_pinball', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='VideoPinball-ramNoFrameskip', version=4)\n",
            "EnvSpec(id='WizardOfWor-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'wizard_of_wor', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='WizardOfWor', version=0)\n",
            "EnvSpec(id='WizardOfWorDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'wizard_of_wor', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='WizardOfWorDeterministic', version=0)\n",
            "EnvSpec(id='WizardOfWorNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'wizard_of_wor', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='WizardOfWorNoFrameskip', version=0)\n",
            "EnvSpec(id='WizardOfWor-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'wizard_of_wor', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='WizardOfWor', version=4)\n",
            "EnvSpec(id='WizardOfWorDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'wizard_of_wor', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='WizardOfWorDeterministic', version=4)\n",
            "EnvSpec(id='WizardOfWorNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'wizard_of_wor', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='WizardOfWorNoFrameskip', version=4)\n",
            "EnvSpec(id='WizardOfWor-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'wizard_of_wor', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='WizardOfWor-ram', version=0)\n",
            "EnvSpec(id='WizardOfWor-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'wizard_of_wor', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='WizardOfWor-ramDeterministic', version=0)\n",
            "EnvSpec(id='WizardOfWor-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'wizard_of_wor', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='WizardOfWor-ramNoFrameskip', version=0)\n",
            "EnvSpec(id='WizardOfWor-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'wizard_of_wor', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='WizardOfWor-ram', version=4)\n",
            "EnvSpec(id='WizardOfWor-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'wizard_of_wor', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='WizardOfWor-ramDeterministic', version=4)\n",
            "EnvSpec(id='WizardOfWor-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'wizard_of_wor', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='WizardOfWor-ramNoFrameskip', version=4)\n",
            "EnvSpec(id='YarsRevenge-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'yars_revenge', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='YarsRevenge', version=0)\n",
            "EnvSpec(id='YarsRevengeDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'yars_revenge', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='YarsRevengeDeterministic', version=0)\n",
            "EnvSpec(id='YarsRevengeNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'yars_revenge', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='YarsRevengeNoFrameskip', version=0)\n",
            "EnvSpec(id='YarsRevenge-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'yars_revenge', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='YarsRevenge', version=4)\n",
            "EnvSpec(id='YarsRevengeDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'yars_revenge', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='YarsRevengeDeterministic', version=4)\n",
            "EnvSpec(id='YarsRevengeNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'yars_revenge', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='YarsRevengeNoFrameskip', version=4)\n",
            "EnvSpec(id='YarsRevenge-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'yars_revenge', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='YarsRevenge-ram', version=0)\n",
            "EnvSpec(id='YarsRevenge-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'yars_revenge', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='YarsRevenge-ramDeterministic', version=0)\n",
            "EnvSpec(id='YarsRevenge-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'yars_revenge', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='YarsRevenge-ramNoFrameskip', version=0)\n",
            "EnvSpec(id='YarsRevenge-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'yars_revenge', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='YarsRevenge-ram', version=4)\n",
            "EnvSpec(id='YarsRevenge-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'yars_revenge', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='YarsRevenge-ramDeterministic', version=4)\n",
            "EnvSpec(id='YarsRevenge-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'yars_revenge', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='YarsRevenge-ramNoFrameskip', version=4)\n",
            "EnvSpec(id='Zaxxon-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'zaxxon', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Zaxxon', version=0)\n",
            "EnvSpec(id='ZaxxonDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'zaxxon', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='ZaxxonDeterministic', version=0)\n",
            "EnvSpec(id='ZaxxonNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'zaxxon', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='ZaxxonNoFrameskip', version=0)\n",
            "EnvSpec(id='Zaxxon-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'zaxxon', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Zaxxon', version=4)\n",
            "EnvSpec(id='ZaxxonDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'zaxxon', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='ZaxxonDeterministic', version=4)\n",
            "EnvSpec(id='ZaxxonNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'zaxxon', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='ZaxxonNoFrameskip', version=4)\n",
            "EnvSpec(id='Zaxxon-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'zaxxon', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Zaxxon-ram', version=0)\n",
            "EnvSpec(id='Zaxxon-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'zaxxon', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Zaxxon-ramDeterministic', version=0)\n",
            "EnvSpec(id='Zaxxon-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'zaxxon', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Zaxxon-ramNoFrameskip', version=0)\n",
            "EnvSpec(id='Zaxxon-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'zaxxon', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Zaxxon-ram', version=4)\n",
            "EnvSpec(id='Zaxxon-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'zaxxon', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Zaxxon-ramDeterministic', version=4)\n",
            "EnvSpec(id='Zaxxon-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'zaxxon', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Zaxxon-ramNoFrameskip', version=4)\n",
            "EnvSpec(id='CartPole-v0', entry_point='gym.envs.classic_control.cartpole:CartPoleEnv', reward_threshold=195.0, nondeterministic=False, max_episode_steps=200, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='CartPole', version=0)\n",
            "EnvSpec(id='CartPole-v1', entry_point='gym.envs.classic_control.cartpole:CartPoleEnv', reward_threshold=475.0, nondeterministic=False, max_episode_steps=500, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='CartPole', version=1)\n",
            "EnvSpec(id='MountainCar-v0', entry_point='gym.envs.classic_control.mountain_car:MountainCarEnv', reward_threshold=-110.0, nondeterministic=False, max_episode_steps=200, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='MountainCar', version=0)\n",
            "EnvSpec(id='MountainCarContinuous-v0', entry_point='gym.envs.classic_control.continuous_mountain_car:Continuous_MountainCarEnv', reward_threshold=90.0, nondeterministic=False, max_episode_steps=999, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='MountainCarContinuous', version=0)\n",
            "EnvSpec(id='Pendulum-v1', entry_point='gym.envs.classic_control.pendulum:PendulumEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=200, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='Pendulum', version=1)\n",
            "EnvSpec(id='Acrobot-v1', entry_point='gym.envs.classic_control.acrobot:AcrobotEnv', reward_threshold=-100.0, nondeterministic=False, max_episode_steps=500, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='Acrobot', version=1)\n",
            "EnvSpec(id='LunarLander-v2', entry_point='gym.envs.box2d.lunar_lander:LunarLander', reward_threshold=200, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='LunarLander', version=2)\n",
            "EnvSpec(id='LunarLanderContinuous-v2', entry_point='gym.envs.box2d.lunar_lander:LunarLander', reward_threshold=200, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'continuous': True}, namespace=None, name='LunarLanderContinuous', version=2)\n",
            "EnvSpec(id='BipedalWalker-v3', entry_point='gym.envs.box2d.bipedal_walker:BipedalWalker', reward_threshold=300, nondeterministic=False, max_episode_steps=1600, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='BipedalWalker', version=3)\n",
            "EnvSpec(id='BipedalWalkerHardcore-v3', entry_point='gym.envs.box2d.bipedal_walker:BipedalWalker', reward_threshold=300, nondeterministic=False, max_episode_steps=2000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'hardcore': True}, namespace=None, name='BipedalWalkerHardcore', version=3)\n",
            "EnvSpec(id='CarRacing-v2', entry_point='gym.envs.box2d.car_racing:CarRacing', reward_threshold=900, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='CarRacing', version=2)\n",
            "EnvSpec(id='Blackjack-v1', entry_point='gym.envs.toy_text.blackjack:BlackjackEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=None, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'sab': True, 'natural': False}, namespace=None, name='Blackjack', version=1)\n",
            "EnvSpec(id='FrozenLake-v1', entry_point='gym.envs.toy_text.frozen_lake:FrozenLakeEnv', reward_threshold=0.7, nondeterministic=False, max_episode_steps=100, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'map_name': '4x4'}, namespace=None, name='FrozenLake', version=1)\n",
            "EnvSpec(id='FrozenLake8x8-v1', entry_point='gym.envs.toy_text.frozen_lake:FrozenLakeEnv', reward_threshold=0.85, nondeterministic=False, max_episode_steps=200, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'map_name': '8x8'}, namespace=None, name='FrozenLake8x8', version=1)\n",
            "EnvSpec(id='CliffWalking-v0', entry_point='gym.envs.toy_text.cliffwalking:CliffWalkingEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=None, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='CliffWalking', version=0)\n",
            "EnvSpec(id='Taxi-v3', entry_point='gym.envs.toy_text.taxi:TaxiEnv', reward_threshold=8, nondeterministic=False, max_episode_steps=200, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='Taxi', version=3)\n",
            "EnvSpec(id='Reacher-v2', entry_point='gym.envs.mujoco:ReacherEnv', reward_threshold=-3.75, nondeterministic=False, max_episode_steps=50, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='Reacher', version=2)\n",
            "EnvSpec(id='Reacher-v4', entry_point='gym.envs.mujoco.reacher_v4:ReacherEnv', reward_threshold=-3.75, nondeterministic=False, max_episode_steps=50, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='Reacher', version=4)\n",
            "EnvSpec(id='Pusher-v2', entry_point='gym.envs.mujoco:PusherEnv', reward_threshold=0.0, nondeterministic=False, max_episode_steps=100, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='Pusher', version=2)\n",
            "EnvSpec(id='Pusher-v4', entry_point='gym.envs.mujoco.pusher_v4:PusherEnv', reward_threshold=0.0, nondeterministic=False, max_episode_steps=100, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='Pusher', version=4)\n",
            "EnvSpec(id='InvertedPendulum-v2', entry_point='gym.envs.mujoco:InvertedPendulumEnv', reward_threshold=950.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='InvertedPendulum', version=2)\n",
            "EnvSpec(id='InvertedPendulum-v4', entry_point='gym.envs.mujoco.inverted_pendulum_v4:InvertedPendulumEnv', reward_threshold=950.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='InvertedPendulum', version=4)\n",
            "EnvSpec(id='InvertedDoublePendulum-v2', entry_point='gym.envs.mujoco:InvertedDoublePendulumEnv', reward_threshold=9100.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='InvertedDoublePendulum', version=2)\n",
            "EnvSpec(id='InvertedDoublePendulum-v4', entry_point='gym.envs.mujoco.inverted_double_pendulum_v4:InvertedDoublePendulumEnv', reward_threshold=9100.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='InvertedDoublePendulum', version=4)\n",
            "EnvSpec(id='HalfCheetah-v2', entry_point='gym.envs.mujoco:HalfCheetahEnv', reward_threshold=4800.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='HalfCheetah', version=2)\n",
            "EnvSpec(id='HalfCheetah-v3', entry_point='gym.envs.mujoco.half_cheetah_v3:HalfCheetahEnv', reward_threshold=4800.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='HalfCheetah', version=3)\n",
            "EnvSpec(id='HalfCheetah-v4', entry_point='gym.envs.mujoco.half_cheetah_v4:HalfCheetahEnv', reward_threshold=4800.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='HalfCheetah', version=4)\n",
            "EnvSpec(id='Hopper-v2', entry_point='gym.envs.mujoco:HopperEnv', reward_threshold=3800.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='Hopper', version=2)\n",
            "EnvSpec(id='Hopper-v3', entry_point='gym.envs.mujoco.hopper_v3:HopperEnv', reward_threshold=3800.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='Hopper', version=3)\n",
            "EnvSpec(id='Hopper-v4', entry_point='gym.envs.mujoco.hopper_v4:HopperEnv', reward_threshold=3800.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='Hopper', version=4)\n",
            "EnvSpec(id='Swimmer-v2', entry_point='gym.envs.mujoco:SwimmerEnv', reward_threshold=360.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='Swimmer', version=2)\n",
            "EnvSpec(id='Swimmer-v3', entry_point='gym.envs.mujoco.swimmer_v3:SwimmerEnv', reward_threshold=360.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='Swimmer', version=3)\n",
            "EnvSpec(id='Swimmer-v4', entry_point='gym.envs.mujoco.swimmer_v4:SwimmerEnv', reward_threshold=360.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='Swimmer', version=4)\n",
            "EnvSpec(id='Walker2d-v2', entry_point='gym.envs.mujoco:Walker2dEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='Walker2d', version=2)\n",
            "EnvSpec(id='Walker2d-v3', entry_point='gym.envs.mujoco.walker2d_v3:Walker2dEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='Walker2d', version=3)\n",
            "EnvSpec(id='Walker2d-v4', entry_point='gym.envs.mujoco.walker2d_v4:Walker2dEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='Walker2d', version=4)\n",
            "EnvSpec(id='Ant-v2', entry_point='gym.envs.mujoco:AntEnv', reward_threshold=6000.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='Ant', version=2)\n",
            "EnvSpec(id='Ant-v3', entry_point='gym.envs.mujoco.ant_v3:AntEnv', reward_threshold=6000.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='Ant', version=3)\n",
            "EnvSpec(id='Ant-v4', entry_point='gym.envs.mujoco.ant_v4:AntEnv', reward_threshold=6000.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='Ant', version=4)\n",
            "EnvSpec(id='Humanoid-v2', entry_point='gym.envs.mujoco:HumanoidEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='Humanoid', version=2)\n",
            "EnvSpec(id='Humanoid-v3', entry_point='gym.envs.mujoco.humanoid_v3:HumanoidEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='Humanoid', version=3)\n",
            "EnvSpec(id='Humanoid-v4', entry_point='gym.envs.mujoco.humanoid_v4:HumanoidEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='Humanoid', version=4)\n",
            "EnvSpec(id='HumanoidStandup-v2', entry_point='gym.envs.mujoco:HumanoidStandupEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='HumanoidStandup', version=2)\n",
            "EnvSpec(id='HumanoidStandup-v4', entry_point='gym.envs.mujoco.humanoidstandup_v4:HumanoidStandupEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='HumanoidStandup', version=4)\n",
            "Total envs available: 940\n"
          ]
        }
      ],
      "source": [
        "envs = gym.envs.registry.values()\n",
        "[print(env) for env in envs]\n",
        "print('Total envs available:', len(envs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCjU1dfJX9zc"
      },
      "source": [
        "### Let's play some old videogames\n",
        "![img](https://github.com/yandexdataschool/Practical_RL/raw/master/yet_another_week/_resource/nerd.png)\n",
        "\n",
        "This time we're gonna apply approximate Q-learning to an Atari game called Breakout. It's not the hardest thing out there, but it's definitely way more complex than anything we tried before.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FemkIIjKX9zd"
      },
      "outputs": [],
      "source": [
        "ENV_NAME = \"BreakoutNoFrameskip-v4\"\n",
        "\n",
        "def make_env(seed=42):\n",
        "    # some envs are wrapped with a time limit wrapper by default\n",
        "    env = gym.make(ENV_NAME).unwrapped\n",
        "    if seed is not None:\n",
        "        env.seed(seed)\n",
        "    return env"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QEsGJ5DX9zf"
      },
      "source": [
        "## Preprocessing (3 pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m32dELZAX9zw"
      },
      "source": [
        "\n",
        "Let's see what observations look like."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 618
        },
        "id": "kuIGAEJCX9zx",
        "outputId": "6dfbeb7b-4aaa-4d91-8054-f4ed37e7de49"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.8/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.8/dist-packages/gym/core.py:43: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.8/dist-packages/gym/utils/passive_env_checker.py:297: UserWarning: \u001b[33mWARN: No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
            "  logger.deprecation(\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1152x648 with 10 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "env = gym.make(ENV_NAME)\n",
        "env.reset()\n",
        "\n",
        "n_cols = 5\n",
        "n_rows = 2\n",
        "fig = plt.figure(figsize=(16, 9))\n",
        "\n",
        "for row in range(n_rows):\n",
        "    for col in range(n_cols):\n",
        "        ax = fig.add_subplot(n_rows, n_cols, row * n_cols + col + 1)\n",
        "        ax.imshow(env.render('rgb_array'))\n",
        "        env.step(env.action_space.sample())\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMNjpBFJX9z2"
      },
      "source": [
        "**Let's play a little.**\n",
        "\n",
        "Pay attention to zoom and fps args of play function. Control: A, D, space."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfzQpzIyX9z3"
      },
      "outputs": [],
      "source": [
        "# # Does not work in Colab.\n",
        "# # Use KeyboardInterrupt (Kernel → Interrupt in Jupyter) to continue.\n",
        "\n",
        "# from gym.utils.play import play\n",
        "\n",
        "# play(env=gym.make(ENV_NAME), zoom=5, fps=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDjoXt8NX9z4"
      },
      "source": [
        "### Processing game image \n",
        "\n",
        "Raw Atari images are large, 210x160x3 by default. However, we don't need that level of detail in order to learn from them.\n",
        "\n",
        "We can thus save a lot of time by preprocessing game image, including\n",
        "* Resizing to a smaller shape, 64x64\n",
        "* Converting to grayscale\n",
        "* Cropping irrelevant image parts (top, bottom and edges)\n",
        "\n",
        "Also please keep one dimension for channel so that final shape would be 1x64x64.\n",
        "\n",
        "Tip: You can implement your own grayscale converter and assign a huge weight to the red channel. This dirty trick is not necessary but it will speed up learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UIEBysDnX9z5"
      },
      "outputs": [],
      "source": [
        "from gym.core import ObservationWrapper\n",
        "from gym.spaces import Box\n",
        "from skimage.transform import resize \n",
        "\n",
        "class PreprocessAtariObs(ObservationWrapper):\n",
        "    def __init__(self, env):\n",
        "        \"\"\"A gym wrapper that crops, scales image into the desired shapes and grayscales it.\"\"\"\n",
        "        ObservationWrapper.__init__(self, env)\n",
        "\n",
        "        self.img_size = (1, 64, 64)\n",
        "        self.observation_space = Box(0.0, 1.0, self.img_size)\n",
        "\n",
        "\n",
        "    def _to_gray_scale(self, rgb, channel_weights=[0.98, 0.01, 0.01]):\n",
        "        #### <YOUR CODE> ####\n",
        "        return np.average(rgb, axis = 2, weights = channel_weights)\n",
        "\n",
        "\n",
        "    def observation(self, img):\n",
        "        \"\"\"what happens to each observation\"\"\"\n",
        "\n",
        "        # Here's what you need to do:\n",
        "        #  * crop image, remove irrelevant parts\n",
        "        #  * resize image to self.img_size\n",
        "        #     (Use imresize from any library you want,\n",
        "        #      e.g. opencv, PIL, keras. Don't use skimage.imresize\n",
        "        #      because it is extremely slow.)\n",
        "        #  * cast image to grayscale\n",
        "        #  * convert image pixels to (0,1) range, float32 type\n",
        "        \n",
        "        #### <YOUR CODE> ####\n",
        "\n",
        "        #  * crop image, remove irrelevant parts\n",
        "        img = img[34:-16, 7: -7, :]        \n",
        "\n",
        "        #  * cast image to grayscale\n",
        "        img = self._to_gray_scale(img)        \n",
        "\n",
        "        #  * resize image to self.img_size\n",
        "        img = resize(img, self.img_size[1:])\n",
        "        img = np.expand_dims(img, axis=0)\n",
        "        img = img/255 \n",
        "\n",
        "        return img.astype(np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "id": "XKnHuUk5X9z7",
        "outputId": "832fb7d0-864e-459c-bf3b-78ab98e09799"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.8/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.8/dist-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
            "  logger.deprecation(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Formal tests seem fine. Here's an example of what you'll get.\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1152x648 with 10 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import gym\n",
        "# spawn game instance for tests\n",
        "env = gym.make(ENV_NAME)  # create raw env\n",
        "env = PreprocessAtariObs(env)\n",
        "observation_shape = env.observation_space.shape\n",
        "n_actions = env.action_space.n\n",
        "env.reset()\n",
        "obs, _, _, _ = env.step(env.action_space.sample())\n",
        "\n",
        "# test observation\n",
        "assert obs.ndim == 3, \"observation must be [channel, h, w] even if there's just one channel\"\n",
        "assert obs.shape == observation_shape, obs.shape\n",
        "assert obs.dtype == 'float32'\n",
        "assert len(np.unique(obs)) > 2, \"your image must not be binary\"\n",
        "assert 0 <= np.min(obs) and np.max(\n",
        "    obs) <= 1, \"convert image pixels to [0,1] range\"\n",
        "\n",
        "assert np.max(obs) >= 0.5, \"It would be easier to see a brighter observation\"\n",
        "assert np.mean(obs) >= 0.1, \"It would be easier to see a brighter observation\"\n",
        "\n",
        "print(\"Formal tests seem fine. Here's an example of what you'll get.\")\n",
        "\n",
        "n_cols = 5\n",
        "n_rows = 2\n",
        "fig = plt.figure(figsize=(16, 9))\n",
        "obs = env.reset()\n",
        "for row in range(n_rows):\n",
        "    for col in range(n_cols):\n",
        "        ax = fig.add_subplot(n_rows, n_cols, row * n_cols + col + 1)\n",
        "        ax.imshow(obs[0, :, :], interpolation='none', cmap='gray')\n",
        "        obs, _, _, _ = env.step(env.action_space.sample())\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZZDQroOX9z7"
      },
      "source": [
        "### Wrapping."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96Jlif4tX9z8"
      },
      "source": [
        "**About the game:** You have 5 lives and get points for breaking the wall. Higher bricks cost more than the lower ones. There are 4 actions: start game (should be called at the beginning and after each life is lost), move left, move right and do nothing. There are some common wrappers used for Atari environments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJZV5HEVX9z-"
      },
      "outputs": [],
      "source": [
        "import atari_wrappers\n",
        "\n",
        "def PrimaryAtariWrap(env, clip_rewards=True):\n",
        "    assert 'NoFrameskip' in env.spec.id\n",
        "\n",
        "    # This wrapper holds the same action for <skip> frames and outputs\n",
        "    # the maximal pixel value of 2 last frames (to handle blinking\n",
        "    # in some envs)\n",
        "    env = atari_wrappers.MaxAndSkipEnv(env, skip=4)\n",
        "\n",
        "    # This wrapper sends done=True when each life is lost\n",
        "    # (not all the 5 lives that are givern by the game rules).\n",
        "    # It should make easier for the agent to understand that losing is bad.\n",
        "    env = atari_wrappers.EpisodicLifeEnv(env)\n",
        "\n",
        "    # This wrapper laucnhes the ball when an episode starts.\n",
        "    # Without it the agent has to learn this action, too.\n",
        "    # Actually it can but learning would take longer.\n",
        "    env = atari_wrappers.FireResetEnv(env)\n",
        "\n",
        "    # This wrapper transforms rewards to {-1, 0, 1} according to their sign\n",
        "    if clip_rewards:\n",
        "        env = atari_wrappers.ClipRewardEnv(env)\n",
        "\n",
        "    # This wrapper is yours :)\n",
        "    env = PreprocessAtariObs(env)\n",
        "    return env"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkpgHEOwX90H"
      },
      "source": [
        "**Let's see if the game is still playable after applying the wrappers.**\n",
        "At playing the EpisodicLifeEnv wrapper seems not to work but actually it does (because after when life finishes a new ball is dropped automatically - it means that FireResetEnv wrapper understands that a new episode began)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_YJA55YX90J"
      },
      "outputs": [],
      "source": [
        "# # Does not work in Colab.\n",
        "# # Use KeyboardInterrupt (Kernel → Interrupt in Jupyter) to continue.\n",
        "\n",
        "# from gym.utils.play import play\n",
        "\n",
        "# def make_play_env():\n",
        "#     env = gym.make(ENV_NAME)\n",
        "#     env = PrimaryAtariWrap(env)\n",
        "# # in PyTorch images have shape [c, h, w] instead of common [h, w, c]\n",
        "#     env = atari_wrappers.AntiTorchWrapper(env)\n",
        "#     return env\n",
        "\n",
        "# play(make_play_env(), zoom=10, fps=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ky5gJ9mBX90K"
      },
      "source": [
        "### Frame buffer\n",
        "\n",
        "Our agent can only process one observation at a time, so we gotta make sure it contains enough information to find optimal actions. For instance, agent has to react to moving objects so it must be able to measure object's velocity.\n",
        "\n",
        "To do so, we introduce a buffer that stores 4 last images. This time everything is pre-implemented for you, not really by the staff of the course :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2TQXbQ9YX90K"
      },
      "outputs": [],
      "source": [
        "from framebuffer import FrameBuffer\n",
        "\n",
        "def make_env(clip_rewards=True, seed=None):\n",
        "    env = gym.make(ENV_NAME)  # create raw env\n",
        "    if seed is not None:\n",
        "        env.seed(seed)\n",
        "    env = PrimaryAtariWrap(env, clip_rewards)\n",
        "    env = FrameBuffer(env, n_frames=4, dim_order='pytorch')\n",
        "    return env\n",
        "\n",
        "env = make_env()\n",
        "env.reset()\n",
        "n_actions = env.action_space.n\n",
        "state_shape = env.observation_space.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZCkPUaBjX90M",
        "outputId": "d76c17b5-67b7-4d38-c103-734cc67a9975"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/gym/core.py:43: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.8/dist-packages/gym/utils/passive_env_checker.py:297: UserWarning: \u001b[33mWARN: No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\u001b[0m\n",
            "  logger.warn(\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcYAAAJOCAYAAAAtaacBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de5BcZ3mg8eedm2SNZEuybNmWZGRYBWJTIIziwBLAi5NgCIUhlSX2ssEh1AoSqMAuW4RLFSTsZjc3QqCywArsYHaJMWAITookOMYJ2SQYi5sxFrJlsC0JWTej20iame55948+ij+LGc2Muqcvo+dXNTXd55zu/k73aB71OWdOR2YiSZIa+jo9AEmSuolhlCSpYBglSSoYRkmSCoZRkqSCYZQkqWAYpXkgIi6OiCMR0d/psUi9zjBKsxAR10bEXRExEhF7qsu/ERHRyXFl5iOZuTgz650chzQfGEZphiLircAHgD8ELgBWAm8AngcMdXBoklrIMEozEBHnAO8FfiMzP5uZh7Phm5n56swcrZb7hYj4ZkQciojtEfHbxX2sjYiMiNdW834UEW+IiJ+KiHsi4kBE/OlJj/trEbGlWvZvI+JJU4zvxH0PVNf/PiL+e0T8c7WJ9S8j4tyI+GQ1trsjYm1x+w9UYzoUEV+PiOcX886KiJuqMWyJiLdFxI5i/kURcWtE7I2IH0TEb7bkSZc6xDBKM/NcYAHwhWmWGwFeAywFfgH49Yh4xUnL/DSwDvhl4E+AdwE/C1wGvCoiXggQEdcA7wR+ETgP+Efg5lmM+VrgV4BVwFOAfwH+DFgObAHeUyx7N7C+mvfnwGciYmE17z3AWuDJwM8B//HEjSKiD/hL4NvV41wFvCUiXjyLcUpdxTBKM7MC2JeZtRMTqndjByLiWES8ACAz/z4zv5OZE5l5D42QvfCk+/pvmXk8M79EI6Q3Z+aezNxJI37PqpZ7A/A/M3NL9bj/A1g/1bvGSfxZZj6YmQeBvwYezMy/q+7rM8XjkJn/NzP3Z2YtM99H4z8BT61mvwr4H5n5o8zcAXyweIyfAs7LzPdm5lhmfh/4KI0oSz3JMEozsx9YcWJTJUBm/tvMXFrN6wOIiJ+OiDurzYoHacRtxUn3tbu4fGyS64ury08CPlDF9wDwGBA03pnNxEwfh4j4r9Vm0oPVY51TjPsiYHtx2/Lyk4CLToyxuu07aex/lXqSYZRm5l+AUeCaaZb7c+A2YE1mngN8hEbMTsd24PWZubT4Oisz//k0729S1f7Et9F4Z7isiv1BHh/3LmB1cZM1J43xByeNcUlmvrSVY5TayTBKM5CZB4DfAT4UEb8UEUsioi8i1gPDxaJLgMcy83hEXAH8hyYe9iPAOyLiMmgcABQR/76J+5vKEqAG7AUGIuLdwNnF/E9X41gWEauANxXzvgYcjojfqg7S6Y+Ip0fET83BOKW2MIzSDGXmHwD/hca7q93V1/8Gfgs48S7uN4D3RsRh4N00onK6j/d54PeBT0XEIeBe4CWnvQJT+1vgb4D7gYeB4zxxc+l7gR3AD4C/Az5L490z1d9NvozGgTs/APYBH6OxKVbqSeEHFUuajYj4deDazDz5oCJpXvAdo6RTiogLI+J51abjpwJvBT7f6XFJc2Vg+kUkneGGaGwyvgQ4AHwK+FBHRyTNoTnblBoRV9M4fVY/8LHM/L05eSBJklpoTsJYneH/fhpnydhB46wa12XmfS1/MEmSWmiuNqVeAWyrzoJBRHyKxt9/TRrGiPAIIElSW2XmpH9jPFcH36ziiYd77+Cks3VExMaI2BwRm+doDJIkzVrHDr7JzE3AJvAdoySpe8zVO8adPPG0UauraZIkdbW5CuPdwLqIuCQihmicaf+2OXosSZJaZk42pWZmLSLeRONUU/3AjZn53bl4LEmSWqkrTgnnPkZJUru1+6hUSZJ6kmGUJKlgGCVJKhhGSZIKhlGSpIIfO3UG6uvrY9myZZxzTvs/ZD0zOXDgAAcOHGC6I6LPOussVqxYweDgYJtG97jR0VH27dvH6OjoKZfrleeyF/hcdsbixYtZvnw5AwOnzsHY2Bj79+/n2LFjbRpZ5xjGM9Dg4CDPfOYzWb9+PRGTHq08Z2q1GnfddRd333039Xr9lMtecMEFXHnllSxfvrxNo3vcrl27+PKXv8yjjz56yuV65bnsBT6XnbF69Wpe+MIXsnjx4lMut3//fu68804efvjhNo2scwzjGaivr4+lS5dy0UUX0dfX3q3p4+PjnH322TP6xbdgwQJWrlzJ+eef34aRPVGtVmNoaGja5XrluewFPpedsWjRIi644IJp36kPDAywcOHCNo2qs9zHKElSwTBKklRwU6qmlJmMjo5y5MiRafe7DAwMsHjxYhYsWNCm0T2uXq9z5MgRjh8/fsrlIoKzzjqL4eHhtm+q65XnshfM5rmcqVqtxsjIyBl34I0mZxh1Stu3b+euu+5iZGTklMstW7aM5z73uaxZs+aUy82FY8eOcffdd/Pggw+ecrm+vj4uu+wynv3sZ3ckOr3wXPaKmT6XM5WZ7N+/n4mJiZbcn3qbYdQpHTp0iG3btnHo0KFTLnf++efzjGc8o02jeqJarcYPf/hDtm7desrlIoIVK1Z07JdfLzyXvWKmz6V0OtzHKElSwTBKklRwU6qknjM4OMjw8HBLN4uPjY0xNjbWsvtT7zKMknrORRddxFVXXcX4+HhL7q9er7Nlyxa2bNniATgyjJJ6S0Rw7rnncu6557bsPsfHxzl48CBbt241jDKMknpPq0/dFhFn5OngNDkPvpEkqeA7RkldITOp1+uMj4+37N1bRNDf39/2Mx2ptxlGSV2hVquxdetWjh492rIwDg8P85M/+ZOsWLGiJfenM4NhlNQVarUa999/P9u2bWvZfZ5//vmsXLnSMGpWDKOkrjExMdHSo0JrtZpHmWrW3PAuSVLBMGpaM9nf0+nD3Wc6xk7rhedyPvG51OlwU6pOacWKFVx++eXTftbhkiVLOOecc9o0qicaGhpi3bp1LFy48JTLRQRr166lv7+/TSN7ol54Ljupv7+fiy++mJUrV7YsZmfqc6nmGEad0qpVqzjvvPOm3U/T19fH0NBQm0b1RAsXLmT9+vU8/elPP+VyEcHAwACDg4NtGtkT9cJz2UmDg4NceumlXHHFFS0L45n6XKo5hlFTOhGSgYHu/jHp6+ub9t1ip/XKc9lJEcGCBQsYHh727w7VUf70SZJUMIySJBXcrnMGqtfr7Nq1i/vuu6/tR+zV63X27t07o78tO3LkCNu2bWPv3r1tGNkT7d27l2PHjk27XK88l73A57IzDh48yP3338+iRYtOudyBAwc4cuRIm0bVWZGZnR4DEdH5QZxBIoJFixaxcOHCtv8CykyOHj06o+gMDg6yePHijhxFOj4+zsjICLVa7ZTL9cpz2Qt8Ljtjpvt1a7UaIyMjLfsMzG6QmZP+oBlGSdIZaaowuo9RkqSCYZQkqdAVB98MDg6ycuXKTg9DknSG2L1795TzuiKMy5Yt45WvfGWnhyFJOkPccsstU87rijAODQ1xySWXdHoYkqQzxKlOFeg+RkmSCoZRkqSCYZQkqWAYJUkqGEZJkgqGUZKkgmGUJKlgGCVJKhhGSZIKhlGSpIJhlCSpYBglSSoYRkmSCoZRkqSCYZQkqWAYJUkqGEZJkgqnHcaIWBMRd0bEfRHx3Yh4czX9tyNiZ0R8q/p6aeuGK0nS3Bpo4rY14K2Z+Y2IWAJ8PSJur+a9PzP/qPnhSZLUXqcdxszcBeyqLh+OiC3AqlYNTJKkTmjJPsaIWAs8C7irmvSmiLgnIm6MiGVT3GZjRGyOiM0jIyOtGIYkSU1rOowRsRi4FXhLZh4CPgw8BVhP4x3l+ya7XWZuyswNmblheHi42WFIktQSTYUxIgZpRPGTmfk5gMzcnZn1zJwAPgpc0fwwJUlqj2aOSg3gBmBLZv5xMf3CYrFXAvee/vAkSWqvZo5KfR7wK8B3IuJb1bR3AtdFxHoggYeA1zc1QkmS2qiZo1L/HxCTzPri6Q9HkqTO8sw3kiQVDKMkSQXDKElSwTBKklQwjJIkFQyjJEkFwyhJUsEwSpJUMIySJBUMoyRJhWbOldqVMpPDhw+zZ88earVap4cjSWrS4OAg5513HkuWLKHx+RVza96FEWD79u3ceeedHDlypNNDkSQ1acmSJbzoRS/iaU97Wlseb16G8fjx4+zbt49Dhw51eiiSpCaNjo5y/Pjxtj2e+xglSSoYRkmSCoZRkqSCYZQkqWAYJUkqGEZJkgqGUZKkgmGUJKlgGCVJKhhGSZIKhlGSpIJhlCSpYBglSSoYRkmSCoZRkqSCYZQkqWAYJUkqGEZJkgqGUZKkgmGUJKlgGCVJKhhGSZIKhlGSpIJhlCSpYBglSSoYRkmSCoZRkqSCYZQkqWAYJUkqGEZJkgqGUZKkgmGUJKlgGCVJKhhGSZIKhlGSpIJhlCSpYBglSSoYRkmSCoZRkqSCYZQkqWAYJUkqGEZJkgqGUZKkwkCzdxARDwGHgTpQy8wNEbEcuAVYCzwEvCozf9TsY0mSNNda9Y7x32Xm+szcUF1/O3BHZq4D7qiuS5LU9eZqU+o1wE3V5ZuAV8zR40iS1FKtCGMCX4qIr0fExmrayszcVV1+FFh58o0iYmNEbI6IzSMjIy0YhiRJzWt6HyPwM5m5MyLOB26PiO+VMzMzIyJPvlFmbgI2AaxZs+bH5kuS1AlNv2PMzJ3V9z3A54ErgN0RcSFA9X1Ps48jSVI7NBXGiBiOiCUnLgM/D9wL3AZcXy12PfCFZh5HkqR2aXZT6krg8xFx4r7+PDP/JiLuBj4dEa8DHgZe1eTjSJLUFk2FMTO/Dzxzkun7gauauW9JkjrBM99IklQwjJIkFQyjJEkFwyhJUsEwSpJUMIySJBUMoyRJBcMoSVLBMEqSVGjFp2t0nQD6IohOD0SS1LS+aO9v83kZxtXDw7z4wgsZO/vsTg9FktSkBYsXs3rRorY93rwLYwDrlizh+U9+MgPHj3d6OJKkJo2fdRa7lyzhYJseb96FEWCwr48lg4MMTUx0eiiSpCaNDgywv42bUz34RpKkgmGUJKlgGCVJKhhGSZIKhlGSpIJhlCSpYBglSSoYRkmSCoZRkqSCYZQkqWAYJUkqGEZJkgrz8iTiRJIDE2Tdk4hLUs8byLa+jZufYVxQJ5ePkuN+7JQk9bocDFhQb9vjzcsw5kDCohrUa50eiiSpSdlfa7xrbBP3MUqSVDCMkiQVDKMkSQXDKElSwTBKklQwjJIkFQyjJEkFwyhJUsEwSpJUMIySJBUMoyRJBcMoSVJhXp5E/ISkfSedlSTND/MyjBN9E4wN1sm+9n1MiSRpboz316j3te/zdedlGOv9ExwbGmd8YqzTQ5EkNanWN0i9r31bAOdlGBPIPjekStJ8MNGXEH4eoyRJHWEYJUkqGEZJkgqGUZKkgmGUJKlgGCVJKhhGSZIKhlGSpIJhlCSpYBglSSoYRkmSCoZRkqTCaZ9EPCKeCtxSTHoy8G5gKfCfgL3V9Hdm5hdPe4SnIftgoh8m2njSWUnS3Mi+JKN9j3faYczMrcB6gIjoB3YCnwdeC7w/M/+oJSOcrYD6guTYojr94ecxSlKvq2edej1p10cmtepjp64CHszMhyPamPUpTAwlY4sm6G/jB1tKkuZGfWKC+khCmz5it1VhvBa4ubj+poh4DbAZeGtm/ujkG0TERmAjwLJly1o0jJMfZG7uVpI0fzV98E1EDAEvBz5TTfow8BQam1l3Ae+b7HaZuSkzN2TmhuHh4WaHIUlSS7TiqNSXAN/IzN0Ambk7M+uZOQF8FLiiBY8hSVJbtCKM11FsRo2IC4t5rwTubcFjSJLUFk3tY4yIYeDngNcXk/8gItbTOH7ooZPmSZLU1ZoKY2aOAOeeNO1XmhqRJEkd5JlvJEkqGEZJkgqGUZKkgmGUJKlgGCVJKhhGSZIKhlGSpEKrTiLeNRI4mv0cZCGZfh6jJPW64CwG6aeP9nw2xLwLI8BjDPFQnsN4Luj0UCRJTRrKs1jL0BPPJjOH5mUYa/RxlAFGGez0UCRJTVpAP+Nt/BxB9zFKklQwjJIkFQyjJEkFwyhJUsEwSpJUMIySJBUMoyRJBcMoSVLBMEqSVDCMkiQVDKMkSQXDKElSYV6eRJyJfnJsAdnXvpPOSpLmyMQCmOhv28PNvzBmMHFgJfX9F1Gvd3owkqRm1Qcgl9dhONvygYzzL4wAh89l4qEnMTHqx05JUq+bWDhGDj0Mw/vb8njzM4xA478V7kKVpJ6XAdm+h7MckiQVDKMkSQXDKElSwTBKklQwjJIkFQyjJEkFwyhJUsEwSpJUMIySJBUMoyRJBcMoSVLBMEqSVJiXJxEfHd3PwR8d4OhRP49RknrdokXJ2FidxpnE5/73+jwMY3L44Fa+/8A/cfjwSKcHI0lq0tlnL+apT3kesK4tjzcPwwi12hGOjjzCyJFDnR6KJKlJA/3nUKutb9vjuY9RkqSCYZQkqWAYJUkqGEZJkgqGUZKkgmGUJKlgGCVJKhhGSZIKhlGSpIJhlCSpYBglSSoYRkmSCoZRkqSCYZQkqTCjMEbEjRGxJyLuLaYtj4jbI+KB6vuyanpExAcjYltE3BMRl8/V4CVJarWZvmP8OHD1SdPeDtyRmeuAO6rrAC+h8WmS64CNwIebH6YkSe0xozBm5leAx06afA1wU3X5JuAVxfRPZMNXgaURcWErBitJ0lxrZh/jyszcVV1+FFhZXV4FbC+W21FNe4KI2BgRmyNi88jISBPDkCSpdVpy8E1mJpCzvM2mzNyQmRuGh4dbMQxJkprWTBh3n9hEWn3fU03fCawplltdTZMkqes1E8bbgOury9cDXyimv6Y6OvU5wMFik6skSV1tYCYLRcTNwJXAiojYAbwH+D3g0xHxOuBh4FXV4l8EXgpsA44Cr23xmCVJmjMzCmNmXjfFrKsmWTaBNzYzKEmSOsUz30iSVDCMkiQVDKMkSQXDKElSwTBKklQwjJIkFQyjJEkFwyhJUsEwSpJUMIySJBUMoyRJBcMoSVLBMEqSVDCMkiQVDKMkSQXDKElSwTBKklQwjJIkFQyjJEkFwyhJUsEwSpJUMIySJBUMoyRJBcMoSVLBMEqSVDCMkiQVDKMkSQXDKElSwTBKklQwjJIkFQyjJEkFwyhJUsEwSpJUMIySJBUMoyRJBcMoSVLBMEqSVDCMkiQVDKMkSQXDKElSwTBKklQwjJIkFQyjJEkFwyhJUsEwSpJUMIySJBUMoyRJBcMoSVLBMEqSVDCMkiQVDKMkSQXDKElSwTBKklQwjJIkFQyjJEkFwyhJUmHaMEbEjRGxJyLuLab9YUR8LyLuiYjPR8TSavraiDgWEd+qvj4yl4OXJKnVZvKO8ePA1SdNux14emY+A7gfeEcx78HMXF99vaE1w5QkqT2mDWNmfgV47KRpX8rMWnX1q8DqORibJElt14p9jL8G/HVx/ZKI+GZE/ENEPH+qG0XExojYHBGbR0ZGWjAMSZKaN9DMjSPiXUAN+GQ1aRdwcWbuj4hnA38REZdl5qGTb5uZm4BNAGvWrMlmxiFJUquc9jvGiPhV4GXAqzMzATJzNDP3V5e/DjwI/EQLxilJUlucVhgj4mrgbcDLM/NoMf28iOivLj8ZWAd8vxUDlSSpHabdlBoRNwNXAisiYgfwHhpHoS4Abo8IgK9WR6C+AHhvRIwDE8AbMvOxSe9YkqQuNG0YM/O6SSbfMMWytwK3NjsoSZI6xTPfSJJUMIySJBUMoyRJBcMoSVLBMEqSVDCMkiQVDKMkSQXDKElSwTBKklQwjJIkFQyjJEkFwyhJUsEwSpJUMIySJBUMoyRJBcMoSVLBMEqSVDCMkiQVDKMkSQXDKElSwTBKklQwjJIkFQyjJEkFwyhJUsEwSpJUMIySJBUMoyRJBcMoSVLBMEqSVDCMkiQVDKMkSQXDKElSwTBKklQwjJIkFQyjJEkFwyhJUsEwSpJUMIySJBUMoyRJBcMoSVLBMEqSVDCMkiQVDKMkSQXDKElSwTBKklQwjJIkFQyjJEkFwyhJUsEwSpJUMIySJBUMoyRJBcMoSVLBMEqSVDCMkiQVDKMkSQXDKElSYdowRsSNEbEnIu4tpv12ROyMiG9VXy8t5r0jIrZFxNaIePFcDVySpLkwk3eMHweunmT6+zNzffX1RYCIuBS4Frisus2HIqK/VYOVJGmuTRvGzPwK8NgM7+8a4FOZOZqZPwC2AVc0MT5JktqqmX2Mb4qIe6pNrcuqaauA7cUyO6ppPyYiNkbE5ojYPDIy0sQwJElqndMN44eBpwDrgV3A+2Z7B5m5KTM3ZOaG4eHh0xyGJEmtdVphzMzdmVnPzAngozy+uXQnsKZYdHU1TZKknnBaYYyIC4urrwROHLF6G3BtRCyIiEuAdcDXmhuiJEntMzDdAhFxM3AlsCIidgDvAa6MiPVAAg8BrwfIzO9GxKeB+4Aa8MbMrM/N0CVJar1pw5iZ100y+YZTLP+7wO82MyhJkjrFM99IklQwjJIkFQyjJEkFwyhJUsEwSpJUMIySJBUMoyRJBcMoSVLBMEqSVDCMkiQVDKMkSQXDKElSwTBKklQwjJIkFQyjJEkFwyhJUsEwSpJUMIySJBUMoyRJBcMoSVLBMEqSVDCMkiQVDKMkSQXDKElSwTBKklQwjJIkFQyjJEkFwyhJUsEwSpJUMIySJBUMoyRJBcMoSVLBMEqSVDCMkiQVDKMkSQXDKElSwTBKklQwjJIkFQyjJEkFwyhJUsEwSpJUMIySJBUMoyRJBcMoSVLBMEqSVDCMkiQVDKMkSQXDKElSwTBKklQwjJIkFQyjJEkFwyhJUsEwSpJUMIySJBUMoyRJhWnDGBE3RsSeiLi3mHZLRHyr+nooIr5VTV8bEceKeR+Zy8FLktRqAzNY5uPAnwKfODEhM3/5xOWIeB9wsFj+wcxc36oBSpLUTtOGMTO/EhFrJ5sXEQG8CnhRa4clSVJnNLuP8fnA7sx8oJh2SUR8MyL+ISKeP9UNI2JjRGyOiM0jIyNNDkOSpNaYyabUU7kOuLm4vgu4ODP3R8Szgb+IiMsy89DJN8zMTcAmgDVr1mST45AkqSVO+x1jRAwAvwjccmJaZo5m5v7q8teBB4GfaHaQkiS1SzPvGH8W+F5m7jgxISLOAx7LzHpEPBlYB3y/yTHOK31Af18fUUybyKSWvmmWpG4wbRgj4mbgSmBFROwA3pOZNwDX8sTNqAAvAN4bEePABPCGzHystUPubT9x9tlsOPdcFvb3/+u0h0dG+OrevRyu1To4MkkSzOyo1OummP6rk0y7Fbi1+WHNT0EjjL/8pCdx9uDgv07/p717+e6BA4ZRkrpAswffaJb6Ixjq62NB8Y5x8KRNq5KkzvGUcJIkFQyjJEkFwyhJUsEwSpJUMIySJBUMoyRJBcMoSVLBv2Nss93HjnH3/v0sGnj8qf/ewYMcn5jo4KgkSScYxjZK4J4DB3jk6NEnvFU/Vq9zcGysU8OSJBUMY5sdqdU44qnfJKlruY9RkqSCYZQkqWAYJUkqGEZJkgqGUZKkgmGUJKlgGCVJKhhGSZIKhlGSpIJhlCSpYBglSSoYRkmSCoZRkqSCYZQkqWAYJUkqGEZJkgqGUZKkwkCnB3DCBNmaOwpadU/qUn1ARHR6GFNKIDP9OZRaKZPIhJz7f1ldEcbRvuShBeOtubOEvYN16uGvpflo6dAQz16+nPMWLuz0UKaUmXzv4EG+e/AgtTb8I5bmu/56nWX79nHhI4+07D4Hx8amnNcdYYzk/oVTD3I2Enh0sEate99QqAnnDg3xslWreMayZZ0eypRqExN85pFH2Hr4MLV6vdPDkXpef63Gubt3s6a/v2X3OTQ6OuW8rghjQstClpnUcTPWfNUXwcL+foYHuuJHd1LjExMM9fXh/82kFsmkb2KC/lqtZbtR4hRbczz4RpKkgmGUJKlgGCVJKhhGSZIKhlGSpIJhlCSpYBglSSp07x+DSZM4Vq+z7fDhrv4bwXomPzx2jLpnvZF6kmFUT9l7/DiffvhhzmrhGTBaLYEfjY0xPjHR6aFIOg2GUT1ldGKC7UePdnoYkuYx9zFKklQwjJIkFdyUKknqavVM9o2O8kgLd6OMneIYAMMoSepqR2o1vrhzJ1/bt69l97n7+PEp53VNGNND2yVJkxibmOCBw4d54PDhtjxeV4RxfOQoj/7Lt1tzZwkHH9zOxNh4a+5PknRGiW54p9bX35+Dixe17P4mxsepHR+DLlg3SVJ3ysxJzxXSFWGMiM4PQpJ0RpkqjP65hiRJBcMoSVLBMEqSVDCMkiQVDKMkSQXDKElSYdowRsSaiLgzIu6LiO9GxJur6csj4vaIeKD6vqyaHhHxwYjYFhH3RMTlc70SkiS1ykzeMdaAt2bmpcBzgDdGxKXA24E7MnMdcEd1HeAlwLrqayPw4ZaPWpKkOTJtGDNzV2Z+o7p8GNgCrAKuAW6qFrsJeEV1+RrgE9nwVWBpRFzY8pFLkjQHZrWPMSLWAs8C7gJWZuauatajwMrq8ipge3GzHdW0k+9rY0RsjojNsxyzJElzZsZhjIjFwK3AWzLzUDkvG+eVm9Vp3TJzU2ZuyMwNs7mdJElzaUZhjIhBGlH8ZGZ+rpq8+8Qm0ur7nmr6TmBNcfPV1TRJkrreTI5KDeAGYEtm/nEx6zbg+ury9cAXiumvqY5OfQ5wsNjkKklSV5v20zUi4meAfwS+A0xUk99JYz/jp4GLgYeBV2XmY1VI/xS4GjgKvDYzT7kf0U/XkCS1mx87JUlSwY+dkiRpBgyjJEkFwyhJUsEwSpJUMIySJBUMoyRJBcMoSVLBMEqSVDCMkiQVDKMkSQXDKElSwTBKklQwjJIkFQyjJEkFwyhJUsEwSpJUMIySJBUMoyRJBcMoSVJhoNMDqOwDHgZWVJfng/m0LuD6dLv5tD7zaV3A9elWT5pqRmRmOwdyShGxOTM3dHocrTCf1gVcn243n9ZnPq0LuD69yE2pkiQVDKMkSYVuC+OmTpvp8icAAATuSURBVA+ghebTuoDr0+3m0/rMp3UB16fndNU+RkmSOq3b3jFKktRRhlGSpEJXhDEiro6IrRGxLSLe3unxzFZErImIOyPivoj4bkS8uZq+PCJuj4gHqu/LOj3WmYqI/oj4ZkT8VXX9koi4q3qNbomIoU6PcaYiYmlEfDYivhcRWyLiuT3+2vzn6ufs3oi4OSIW9tLrExE3RsSeiLi3mDbp6xENH6zW656IuLxzI5/cFOvzh9XP2z0R8fmIWFrMe0e1Plsj4sWdGfXUJlufYt5bIyIjYkV1vetfn9PR8TBGRD/wv4CXAJcC10XEpZ0d1azVgLdm5qXAc4A3VuvwduCOzFwH3FFd7xVvBrYU138feH9m/hvgR8DrOjKq0/MB4G8y82nAM2msV0++NhGxCvhNYENmPh3oB66lt16fjwNXnzRtqtfjJcC66msj8OE2jXE2Ps6Pr8/twNMz8xnA/cA7AKrfC9cCl1W3+VD1O7CbfJwfXx8iYg3w88AjxeReeH1mreNhBK4AtmXm9zNzDPgUcE2HxzQrmbkrM79RXT5M4xfvKhrrcVO12E3AKzozwtmJiNXALwAfq64H8CLgs9UivbQu5wAvAG4AyMyxzDxAj742lQHgrIgYABYBu+ih1yczvwI8dtLkqV6Pa4BPZMNXgaURcWF7Rjozk61PZn4pM2vV1a8Cq6vL1wCfyszRzPwBsI3G78CuMcXrA/B+4G1AecRm178+p6MbwrgK2F5c31FN60kRsRZ4FnAXsDIzd1WzHgVWdmhYs/UnNP4BTFTXzwUOFP/Qe+k1ugTYC/xZtWn4YxExTI++Npm5E/gjGv9r3wUcBL5O774+J0z1esyH3w+/Bvx1dbkn1ycirgF2Zua3T5rVk+sznW4I47wREYuBW4G3ZOahcl42/i6m6/82JiJeBuzJzK93eiwtMgBcDnw4M58FjHDSZtNeeW0Aqn1v19AI/kXAMJNs9uplvfR6TCci3kVjV8snOz2W0xURi4B3Au/u9FjapRvCuBNYU1xfXU3rKRExSCOKn8zMz1WTd5/YrFB939Op8c3C84CXR8RDNDZrv4jGPrql1aY76K3XaAewIzPvqq5/lkYoe/G1AfhZ4AeZuTczx4HP0XjNevX1OWGq16Nnfz9ExK8CLwNenY//wXgvrs9TaPxH7NvV74XVwDci4gJ6c32m1Q1hvBtYVx1VN0Rjx/RtHR7TrFT74G4AtmTmHxezbgOury5fD3yh3WObrcx8R2auzsy1NF6LL2fmq4E7gV+qFuuJdQHIzEeB7RHx1GrSVcB99OBrU3kEeE5ELKp+7k6sT0++PoWpXo/bgNdURz8+BzhYbHLtWhFxNY3dES/PzKPFrNuAayNiQURcQuOgla91YowzlZnfyczzM3Nt9XthB3B59W+rJ1+faWVmx7+Al9I4cutB4F2dHs9pjP9naGz6uQf4VvX1Uhr75u4AHgD+Dlje6bHOcr2uBP6quvxkGv+AtwGfARZ0enyzWI/1wObq9fkLYFkvvzbA7wDfA+4F/g+woJdeH+BmGvtHx2n8kn3dVK8HEDSOWn8Q+A6No3E7vg4zWJ9tNPa9nfh98JFi+XdV67MVeEmnxz+T9Tlp/kPAil55fU7ny1PCSZJU6IZNqZIkdQ3DKElSwTBKklQwjJIkFQyjJEkFwyhJUsEwSpJU+P/7hbI8BUybFwAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 864x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1080x1080 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "for _ in range(12):\n",
        "    obs, _, _, _ = env.step(env.action_space.sample())\n",
        "\n",
        "plt.figure(figsize=[12,10])\n",
        "plt.title(\"Game image\")\n",
        "plt.imshow(env.render(\"rgb_array\"))\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=[15,15])\n",
        "plt.title(\"Agent observation (4 frames top to bottom)\")\n",
        "plt.imshow(utils.img_by_obs(obs, state_shape), cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGFfiPnTX90N"
      },
      "source": [
        "## DQN as it is (4 pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HijJ_V4EX90N"
      },
      "source": [
        "### Building a network\n",
        "\n",
        "We now need to build a neural network that can map images to state q-values. This network will be called on every agent's step so it better not be resnet-152 unless you have an array of GPUs. Instead, you can use strided convolutions with a small number of features to save time and memory.\n",
        "\n",
        "You can build any architecture you want, but for reference, here's something that will more or less work:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4K8X1uY1X90N"
      },
      "source": [
        "![img](https://github.com/yandexdataschool/Practical_RL/raw/master/yet_another_week/_resource/dqn_arch.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jQO2gIiX90O"
      },
      "source": [
        "**Dueling network: (+2 pts)**\n",
        "$$Q_{\\theta}(s, a) = V_{\\eta}(f_{\\xi}(s)) + A_{\\psi}(f_{\\xi}(s), a) - \\frac{\\sum_{a'}A_{\\psi}(f_{\\xi}(s), a')}{N_{actions}},$$\n",
        "where $\\xi$, $\\eta$, and $\\psi$ are, respectively, the parameters of the\n",
        "shared encoder $f_ξ$ , of the value stream $V_\\eta$ , and of the advan\n",
        "tage stream $A_\\psi$; and $\\theta = \\{\\xi, \\eta, \\psi\\}$ is their concatenation.\n",
        "\n",
        "For the architecture on the image $V$ and $A$ heads can follow the dense layer instead of $Q$. Please don't worry that the model becomes a little bigger."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9R6HAK4X90P",
        "outputId": "97585ccf-1147-4150-cafb-c44b6e4df84c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# those who have a GPU but feel unfair to use it can uncomment:\n",
        "# device = torch.device('cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MncbspErX90R"
      },
      "outputs": [],
      "source": [
        "class DQNAgent(nn.Module):\n",
        "    def __init__(self, state_shape, n_actions, epsilon=0):\n",
        "\n",
        "        super().__init__()\n",
        "        self.epsilon = epsilon\n",
        "        self.n_actions = n_actions\n",
        "        self.state_shape = state_shape\n",
        "\n",
        "        # Define your network body here. Please make sure agent is fully contained here\n",
        "        # nn.Flatten() can be useful\n",
        "        #### <YOUR CODE> ####\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Conv2d(in_channels = 4, out_channels = 16, kernel_size=3 , stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels = 16, out_channels = 32, kernel_size=3 , stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size=3 , stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(7*7*64, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, self.n_actions)\n",
        "        )\n",
        "        \n",
        "\n",
        "    def forward(self, state_t):\n",
        "        \"\"\"\n",
        "        takes agent's observation (tensor), returns qvalues (tensor)\n",
        "        :param state_t: a batch of 4-frame buffers, shape = [batch_size, 4, h, w]\n",
        "        \"\"\"\n",
        "        # Use your network to compute qvalues for given state\n",
        "        #### <YOUR CODE> ####\n",
        "        qvalues = self.network(state_t)\n",
        "\n",
        "        assert qvalues.requires_grad, \"qvalues must be a torch tensor with grad\"\n",
        "        assert (\n",
        "            len(qvalues.shape) == 2 and \n",
        "            qvalues.shape[0] == state_t.shape[0] and \n",
        "            qvalues.shape[1] == n_actions\n",
        "        )\n",
        "\n",
        "        return qvalues\n",
        "\n",
        "    def get_qvalues(self, states):\n",
        "        \"\"\"\n",
        "        like forward, but works on numpy arrays, not tensors\n",
        "        \"\"\"\n",
        "        model_device = next(self.parameters()).device\n",
        "        states = torch.tensor(states, device=model_device, dtype=torch.float32)\n",
        "        qvalues = self.forward(states)\n",
        "        return qvalues.data.cpu().numpy()\n",
        "\n",
        "    def sample_actions(self, qvalues):\n",
        "        \"\"\"pick actions given qvalues. Uses epsilon-greedy exploration strategy. \"\"\"\n",
        "        epsilon = self.epsilon\n",
        "        batch_size, n_actions = qvalues.shape\n",
        "\n",
        "        random_actions = np.random.choice(n_actions, size=batch_size)\n",
        "        best_actions = qvalues.argmax(axis=-1)\n",
        "\n",
        "        should_explore = np.random.choice(\n",
        "            [0, 1], batch_size, p=[1-epsilon, epsilon])\n",
        "        return np.where(should_explore, random_actions, best_actions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2z_MwiFAX90S"
      },
      "outputs": [],
      "source": [
        "agent = DQNAgent(state_shape, n_actions, epsilon=0.5).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQ8gXhnTX90S"
      },
      "source": [
        "Now let's try out our agent to see if it raises any errors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ckDgmKivX90T"
      },
      "outputs": [],
      "source": [
        "def evaluate(env, agent, n_games=1, greedy=False, t_max=10000):\n",
        "    \"\"\" Plays n_games full games. If greedy, picks actions as argmax(qvalues). Returns mean reward. \"\"\"\n",
        "    rewards = []\n",
        "    for _ in range(n_games):\n",
        "        s = env.reset()\n",
        "        reward = 0\n",
        "        for _ in range(t_max):\n",
        "            qvalues = agent.get_qvalues([s])\n",
        "            action = qvalues.argmax(axis=-1)[0] if greedy else agent.sample_actions(qvalues)[0]\n",
        "            s, r, done, _ = env.step(action)\n",
        "            reward += r\n",
        "            if done:\n",
        "                break\n",
        "\n",
        "        rewards.append(reward)\n",
        "    return np.mean(rewards)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7bWwz48X90U",
        "outputId": "fffe5e93-6187-4d8c-b4a6-183d2cc7c0f1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-18-4d3b4829e378>:49: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  states = torch.tensor(states, device=model_device, dtype=torch.float32)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate(env, agent, n_games=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25tyOImaX90U"
      },
      "source": [
        "### Experience replay\n",
        "For this assignment, we provide you with experience replay buffer. If you implemented experience replay buffer in last week's assignment, you can copy-paste it here **to get 2 bonus points**.\n",
        "\n",
        "![img](https://github.com/yandexdataschool/Practical_RL/raw/master/yet_another_week/_resource/exp_replay.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SavNbyzX90V"
      },
      "source": [
        "#### The interface is fairly simple:\n",
        "* `exp_replay.add(obs, act, rw, next_obs, done)` - saves (s,a,r,s',done) tuple into the buffer\n",
        "* `exp_replay.sample(batch_size)` - returns observations, actions, rewards, next_observations and is_done for `batch_size` random samples.\n",
        "* `len(exp_replay)` - returns number of elements stored in replay buffer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdnAYoyrX90V"
      },
      "outputs": [],
      "source": [
        "from replay_buffer import ReplayBuffer\n",
        "exp_replay = ReplayBuffer(10)\n",
        "\n",
        "for _ in range(30):\n",
        "    exp_replay.add(env.reset(), env.action_space.sample(), 1.0, env.reset(), done=False)\n",
        "\n",
        "obs_batch, act_batch, reward_batch, next_obs_batch, is_done_batch = exp_replay.sample(5)\n",
        "\n",
        "assert len(exp_replay) == 10, \"experience replay size should be 10 because that's what maximum capacity is\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nD-f_mPtX90X"
      },
      "outputs": [],
      "source": [
        "def play_and_record(initial_state, agent, env, exp_replay, n_steps=1):\n",
        "    \"\"\"\n",
        "    Play the game for exactly n_steps, record every (s,a,r,s', done) to replay buffer. \n",
        "    Whenever game ends, add record with done=True and reset the game.\n",
        "    It is guaranteed that env has done=False when passed to this function.\n",
        "\n",
        "    PLEASE DO NOT RESET ENV UNLESS IT IS \"DONE\"\n",
        "\n",
        "    :returns: return sum of rewards over time and the state in which the env stays\n",
        "    \"\"\"\n",
        "    s = initial_state\n",
        "    sum_rewards = 0\n",
        "\n",
        "    # Play the game for n_steps as per instructions above\n",
        "    #### <YOUR CODE> ####\n",
        "    for _ in range(n_steps):\n",
        "        qvalues = agent.get_qvalues([s])\n",
        "            \n",
        "        a = agent.sample_actions(qvalues)[0]\n",
        "\n",
        "        next_s, r, done, _ = env.step(a)\n",
        "\n",
        "        exp_replay.add(s, a, r, next_s, done)\n",
        "\n",
        "        s = next_s\n",
        "        sum_rewards += r\n",
        "        \n",
        "        if done:\n",
        "            s = env.reset()\n",
        "\n",
        "    return sum_rewards, s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTdWdUArX90a",
        "outputId": "e222027f-c51e-4688-a853-888247756cce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Well done!\n"
          ]
        }
      ],
      "source": [
        "# testing your code.\n",
        "exp_replay = ReplayBuffer(2000)\n",
        "\n",
        "state = env.reset()\n",
        "play_and_record(state, agent, env, exp_replay, n_steps=1000)\n",
        "\n",
        "# if you're using your own experience replay buffer, some of those tests may need correction.\n",
        "# just make sure you know what your code does\n",
        "assert len(exp_replay) == 1000, \\\n",
        "    \"play_and_record should have added exactly 1000 steps, \" \\\n",
        "    \"but instead added %i\" % len(exp_replay)\n",
        "is_dones = list(zip(*exp_replay._storage))[-1]\n",
        "\n",
        "assert 0 < np.mean(is_dones) < 0.1, \\\n",
        "    \"Please make sure you restart the game whenever it is 'done' and \" \\\n",
        "    \"record the is_done correctly into the buffer. Got %f is_done rate over \" \\\n",
        "    \"%i steps. [If you think it's your tough luck, just re-run the test]\" % (\n",
        "        np.mean(is_dones), len(exp_replay))\n",
        "\n",
        "for _ in range(100):\n",
        "    obs_batch, act_batch, reward_batch, next_obs_batch, is_done_batch = exp_replay.sample(10)\n",
        "    assert obs_batch.shape == next_obs_batch.shape == (10,) + state_shape\n",
        "    assert act_batch.shape == (10,), \\\n",
        "        \"actions batch should have shape (10,) but is instead %s\" % str(act_batch.shape)\n",
        "    assert reward_batch.shape == (10,), \\\n",
        "        \"rewards batch should have shape (10,) but is instead %s\" % str(reward_batch.shape)\n",
        "    assert is_done_batch.shape == (10,), \\\n",
        "        \"is_done batch should have shape (10,) but is instead %s\" % str(is_done_batch.shape)\n",
        "    assert [int(i) in (0, 1) for i in is_dones], \\\n",
        "        \"is_done should be strictly True or False\"\n",
        "    assert [0 <= a < n_actions for a in act_batch], \"actions should be within [0, n_actions)\"\n",
        "\n",
        "print(\"Well done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yWyyj5tX90c"
      },
      "source": [
        "### Target networks\n",
        "\n",
        "We also employ the so called \"target network\" - a copy of neural network weights to be used for reference Q-values:\n",
        "\n",
        "The network itself is an exact copy of agent network, but it's parameters are not trained. Instead, they are moved here from agent's actual network every so often.\n",
        "\n",
        "$$ Q_{reference}(s,a) = r + \\gamma \\cdot \\max _{a'} Q_{target}(s',a') $$\n",
        "\n",
        "![img](https://github.com/yandexdataschool/Practical_RL/raw/master/yet_another_week/_resource/target_net.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nEHtGkMX90c",
        "outputId": "5c8eabd0-8d17-43a6-865a-c1e37d4fcdb9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "target_network = DQNAgent(agent.state_shape, agent.n_actions, epsilon=0.5).to(device)\n",
        "# This is how you can load weights from agent into target network\n",
        "target_network.load_state_dict(agent.state_dict())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zXeHHMrX90f"
      },
      "source": [
        "### Learning with... Q-learning\n",
        "Here we write a function similar to `agent.update` from tabular q-learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gY2o1MCMX90g"
      },
      "source": [
        "Compute Q-learning TD error:\n",
        "\n",
        "$$ L = { 1 \\over N} \\sum_i [ Q_{\\theta}(s,a) - Q_{reference}(s,a) ] ^2 $$\n",
        "\n",
        "With Q-reference defined as\n",
        "\n",
        "$$ Q_{reference}(s,a) = r(s,a) + \\gamma \\cdot max_{a'} Q_{target}(s', a') $$\n",
        "\n",
        "Where\n",
        "* $Q_{target}(s',a')$ denotes Q-value of next state and next action predicted by __target_network__\n",
        "* $s, a, r, s'$ are current state, action, reward and next state respectively\n",
        "* $\\gamma$ is a discount factor defined two cells above.\n",
        "\n",
        "\n",
        "__Note 1:__ there's an example input below. Feel free to experiment with it before you write the function.\n",
        "\n",
        "__Note 2:__ compute_td_loss is a source of 99% of bugs in this homework. If reward doesn't improve, it often helps to go through it line by line [with a rubber duck](https://rubberduckdebugging.com/).\n",
        "\n",
        "**Double DQN (+2 pts)**\n",
        "\n",
        "$$ Q_{reference}(s,a) = r(s, a) + \\gamma \\cdot\n",
        "Q_{target}(s',argmax_{a'}Q_\\theta(s', a')) $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LyDN1NiqX90h"
      },
      "outputs": [],
      "source": [
        "def compute_td_loss(states, actions, rewards, next_states, is_done,\n",
        "                    agent, target_network,\n",
        "                    gamma=0.99,\n",
        "                    check_shapes=False,\n",
        "                    device=device):\n",
        "    \"\"\" Compute td loss using torch operations only. Use the formulae above. \"\"\"\n",
        "    states = torch.tensor(states, device=device, dtype=torch.float32)    # shape: [batch_size, *state_shape]\n",
        "    actions = torch.tensor(actions, device=device, dtype=torch.int64)    # shape: [batch_size]\n",
        "    rewards = torch.tensor(rewards, device=device, dtype=torch.float32)  # shape: [batch_size]\n",
        "    # shape: [batch_size, *state_shape]\n",
        "    next_states = torch.tensor(next_states, device=device, dtype=torch.float)\n",
        "    is_done = torch.tensor(\n",
        "        is_done.astype('float32'),\n",
        "        device=device,\n",
        "        dtype=torch.float32,\n",
        "    )  # shape: [batch_size]\n",
        "    is_not_done = 1 - is_done\n",
        "\n",
        "    # get q-values for all actions in current states\n",
        "    predicted_qvalues = agent(states)  # shape: [batch_size, n_actions]\n",
        "\n",
        "    # compute q-values for all actions in next states\n",
        "    predicted_next_qvalues = target_network(next_states)  # shape: [batch_size, n_actions]\n",
        "    \n",
        "    # select q-values for chosen actions\n",
        "    predicted_qvalues_for_actions = predicted_qvalues[range(len(actions)), actions]  # shape: [batch_size]\n",
        "\n",
        "    # compute V*(next_states) using predicted next q-values\n",
        "    #### <YOUR CODE> ####\n",
        "    next_state_values = torch.tensor([torch.max(q) for q in predicted_next_qvalues], dtype=torch.float32)\n",
        "\n",
        "    assert next_state_values.dim() == 1 and next_state_values.shape[0] == states.shape[0], \\\n",
        "        \"must predict one value per state\"\n",
        "\n",
        "    # compute \"target q-values\" for loss - it's what's inside square parentheses in the above formula.\n",
        "    # at the last state use the simplified formula: Q(s,a) = r(s,a) since s' doesn't exist\n",
        "    # you can multiply next state values by is_not_done to achieve this.\n",
        "    #### <YOUR CODE> ####\n",
        "    target_qvalues_for_actions = rewards + gamma * next_state_values.to(device) * is_not_done.to(device)\n",
        "\n",
        "    # mean squared error loss to minimize\n",
        "    loss = torch.mean((predicted_qvalues_for_actions - target_qvalues_for_actions.detach()) ** 2)\n",
        "\n",
        "    if check_shapes:\n",
        "        assert predicted_next_qvalues.data.dim() == 2, \\\n",
        "            \"make sure you predicted q-values for all actions in next state\"\n",
        "        assert next_state_values.data.dim() == 1, \\\n",
        "            \"make sure you computed V(s') as maximum over just the actions axis and not all axes\"\n",
        "        assert target_qvalues_for_actions.data.dim() == 1, \\\n",
        "            \"there's something wrong with target q-values, they must be a vector\"\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOJrW1p4X90i"
      },
      "source": [
        "Sanity checks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-WVuce8FX90j"
      },
      "outputs": [],
      "source": [
        "obs_batch, act_batch, reward_batch, next_obs_batch, is_done_batch = exp_replay.sample(10)\n",
        "\n",
        "loss = compute_td_loss(obs_batch, act_batch, reward_batch, next_obs_batch, is_done_batch,\n",
        "                       agent, target_network,\n",
        "                       gamma=0.99, check_shapes=True)\n",
        "loss.backward()\n",
        "\n",
        "assert loss.requires_grad and tuple(loss.data.size()) == (), \\\n",
        "    \"you must return scalar loss - mean over batch\"\n",
        "assert np.any(next(agent.parameters()).grad.data.cpu().numpy() != 0), \\\n",
        "    \"loss must be differentiable w.r.t. network weights\"\n",
        "assert np.all(next(target_network.parameters()).grad is None), \\\n",
        "    \"target network should not have grads\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-t0s7OSX90k"
      },
      "source": [
        "## Main loop (3 pts)\n",
        "\n",
        "**If deadline is tonight and it has not converged:** It is ok. Send the notebook today and when it converges send it again.\n",
        "If the code is exactly the same points will not be discounted.\n",
        "\n",
        "It's time to put everything together and see if it learns anything."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NuXsZN3aX90l"
      },
      "outputs": [],
      "source": [
        "from tqdm import trange\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ezRD6QLX90m",
        "outputId": "1d02375a-1e9d-48d6-cafb-bda4e9fda51d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f755da3b1d0>"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# <YOUR CODE: your favourite random seed>\n",
        "seed = 42\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQKr4hSSX90n",
        "outputId": "3817b1d4-b3ce-4947-b068-f75c3126cee0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "env = make_env(seed)\n",
        "state_shape = env.observation_space.shape\n",
        "n_actions = env.action_space.n\n",
        "state = env.reset()\n",
        "\n",
        "agent = DQNAgent(state_shape, n_actions, epsilon=1).to(device)\n",
        "target_network = DQNAgent(state_shape, n_actions).to(device)\n",
        "target_network.load_state_dict(agent.state_dict())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJh9aPGTX90n"
      },
      "source": [
        "Buffer of size $10^4$ fits into 5 Gb RAM.\n",
        "\n",
        "Larger sizes ($10^5$ and $10^6$ are common) can be used. It can improve the learning, but $10^4$ is quite enough. $10^2$ will probably fail learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SRZqIzBX90o",
        "outputId": "fe5d7174-4bae-4c71-a254-c87005e7a1ba"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 99%|█████████▉| 99/100 [01:34<00:00,  1.05it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "REPLAY_BUFFER_SIZE = 10**4\n",
        "N_STEPS = 100\n",
        "\n",
        "exp_replay = ReplayBuffer(REPLAY_BUFFER_SIZE)\n",
        "for i in trange(REPLAY_BUFFER_SIZE // N_STEPS):\n",
        "    if not utils.is_enough_ram(min_available_gb=0.1):\n",
        "        print(\"\"\"\n",
        "            Less than 100 Mb RAM available. \n",
        "            Make sure the buffer size in not too huge.\n",
        "            Also check, maybe other processes consume RAM heavily.\n",
        "            \"\"\"\n",
        "             )\n",
        "        break\n",
        "    play_and_record(state, agent, env, exp_replay, n_steps=N_STEPS)\n",
        "    if len(exp_replay) == REPLAY_BUFFER_SIZE:\n",
        "        break\n",
        "print(len(exp_replay))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PrHBiYb9X90p"
      },
      "outputs": [],
      "source": [
        "timesteps_per_epoch = 1\n",
        "batch_size = 16\n",
        "total_steps = 3 * 10**6\n",
        "decay_steps = 10**6\n",
        "\n",
        "opt = torch.optim.Adam(agent.parameters(), lr=1e-4)\n",
        "\n",
        "init_epsilon = 0.5\n",
        "final_epsilon = 0.1\n",
        "\n",
        "loss_freq = 50\n",
        "refresh_target_network_freq = 5000\n",
        "eval_freq = 5000\n",
        "\n",
        "max_grad_norm = 50\n",
        "\n",
        "n_lives = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDooSeQZX90q"
      },
      "outputs": [],
      "source": [
        "mean_rw_history = []\n",
        "td_loss_history = []\n",
        "grad_norm_history = []\n",
        "initial_state_v_history = []\n",
        "step = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0iQWD2_X90r"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def wait_for_keyboard_interrupt():\n",
        "    try:\n",
        "        while True:\n",
        "            time.sleep(1)\n",
        "    except KeyboardInterrupt:\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fcO1SeK4XO7Z"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import psutil\n",
        "from scipy.signal import fftconvolve, gaussian\n",
        "\n",
        "\n",
        "def get_cum_discounted_rewards(rewards, gamma):\n",
        "    \"\"\"\n",
        "    evaluates cumulative discounted rewards:\n",
        "    r_t + gamma * r_{t+1} + gamma^2 * r_{t_2} + ...\n",
        "    \"\"\"\n",
        "    cum_rewards = []\n",
        "    cum_rewards.append(rewards[-1])\n",
        "    for r in reversed(rewards[:-1]):\n",
        "        cum_rewards.insert(0, r + gamma * cum_rewards[0])\n",
        "    return cum_rewards\n",
        "\n",
        "\n",
        "def play_and_log_episode(env, agent, gamma=0.99, t_max=10000):\n",
        "    \"\"\"\n",
        "    always greedy\n",
        "    \"\"\"\n",
        "    states = []\n",
        "    v_mc = []\n",
        "    v_agent = []\n",
        "    q_spreads = []\n",
        "    td_errors = []\n",
        "    rewards = []\n",
        "\n",
        "    s = env.reset()\n",
        "    for step in range(t_max):\n",
        "        states.append(s)\n",
        "        qvalues = agent.get_qvalues([s])\n",
        "        max_q_value, min_q_value = np.max(qvalues), np.min(qvalues)\n",
        "        v_agent.append(max_q_value)\n",
        "        q_spreads.append(max_q_value - min_q_value)\n",
        "        if step > 0:\n",
        "            td_errors.append(\n",
        "                np.abs(rewards[-1] + gamma * v_agent[-1] - v_agent[-2]))\n",
        "\n",
        "        action = qvalues.argmax(axis=-1)[0]\n",
        "\n",
        "        s, r, done, _ = env.step(action)\n",
        "        rewards.append(r)\n",
        "        if done:\n",
        "            break\n",
        "    td_errors.append(np.abs(rewards[-1] + gamma * v_agent[-1] - v_agent[-2]))\n",
        "\n",
        "    v_mc = get_cum_discounted_rewards(rewards, gamma)\n",
        "\n",
        "    return_pack = {\n",
        "        'states': np.array(states),\n",
        "        'v_mc': np.array(v_mc),\n",
        "        'v_agent': np.array(v_agent),\n",
        "        'q_spreads': np.array(q_spreads),\n",
        "        'td_errors': np.array(td_errors),\n",
        "        'rewards': np.array(rewards),\n",
        "        'episode_finished': np.array(done)\n",
        "    }\n",
        "\n",
        "    return return_pack\n",
        "\n",
        "\n",
        "def img_by_obs(obs, state_dim):\n",
        "    \"\"\"\n",
        "    Unwraps obs by channels.\n",
        "    observation is of shape [c, h=w, w=h]\n",
        "    \"\"\"\n",
        "    return obs.reshape([-1, state_dim[2]])\n",
        "\n",
        "\n",
        "def is_enough_ram(min_available_gb=0.1):\n",
        "    mem = psutil.virtual_memory()\n",
        "    return mem.available >= min_available_gb * (1024 ** 3)\n",
        "\n",
        "\n",
        "def linear_decay(init_val, final_val, cur_step, total_steps):\n",
        "    if cur_step >= total_steps:\n",
        "        return final_val\n",
        "    return (init_val * (total_steps - cur_step) +\n",
        "            final_val * cur_step) / total_steps\n",
        "\n",
        "\n",
        "def smoothen(values):\n",
        "    kernel = gaussian(100, std=100)\n",
        "    # kernel = np.concatenate([np.arange(100), np.arange(99, -1, -1)])\n",
        "    kernel = kernel / np.sum(kernel)\n",
        "    return fftconvolve(values, kernel, 'valid')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "id": "LKGA2g8qX90s",
        "outputId": "f3741101-7830-4f2d-d318-8a02edd3ff97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "buffer size = 10000, epsilon = 0.41000\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1152x648 with 4 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  8%|▊         | 226547/3000001 [1:13:10<14:55:54, 51.60it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-5b6bd98d987c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mgrad_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_grad_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    155\u001b[0m                     \u001b[0mstate_steps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m             adam(params_with_grad,\n\u001b[0m\u001b[1;32m    158\u001b[0m                  \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m                  \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m     func(params,\n\u001b[0m\u001b[1;32m    214\u001b[0m          \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m          \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable)\u001b[0m\n\u001b[1;32m    303\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m             \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "state = env.reset()\n",
        "with trange(step, total_steps + 1) as progress_bar:\n",
        "    for step in progress_bar:\n",
        "        if not utils.is_enough_ram():\n",
        "            print('less that 100 Mb RAM available, freezing')\n",
        "            print('make sure everything is ok and use KeyboardInterrupt to continue')\n",
        "            wait_for_keyboard_interrupt()\n",
        "\n",
        "        agent.epsilon = utils.linear_decay(init_epsilon, final_epsilon, step, decay_steps)\n",
        "\n",
        "        # play\n",
        "        _, state = play_and_record(state, agent, env, exp_replay, timesteps_per_epoch)\n",
        "\n",
        "        # train\n",
        "        #### <YOUR CODE: sample batch_size of data from experience replay> ####\n",
        "        s_batch, a_batch, r_batch, next_s_batch, done_batch = exp_replay.sample(batch_size)\n",
        "        \n",
        "        #### <YOUR CODE: compute TD loss> ####\n",
        "        loss = compute_td_loss(s_batch, a_batch, r_batch, next_s_batch, done_batch,\n",
        "                       agent, target_network, check_shapes=False)\n",
        "\n",
        "        loss.backward()\n",
        "        grad_norm = nn.utils.clip_grad_norm_(agent.parameters(), max_grad_norm)\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "\n",
        "        if step % loss_freq == 0:\n",
        "            td_loss_history.append(loss.data.cpu().item())\n",
        "            grad_norm_history.append(grad_norm)\n",
        "\n",
        "        if step % refresh_target_network_freq == 0:\n",
        "            # Load agent weights into target_network\n",
        "            #### <YOUR CODE> ####\n",
        "            target_network.load_state_dict(agent.state_dict())\n",
        "\n",
        "        if step % eval_freq == 0:\n",
        "            mean_rw_history.append(evaluate(\n",
        "                make_env(clip_rewards=True, seed=step), agent, n_games=3 * n_lives, greedy=True)\n",
        "            )\n",
        "            initial_state_q_values = agent.get_qvalues(\n",
        "                [make_env(seed=step).reset()]\n",
        "            )\n",
        "            initial_state_v_history.append(np.max(initial_state_q_values))\n",
        "\n",
        "            clear_output(True)\n",
        "            print(\"buffer size = %i, epsilon = %.5f\" %\n",
        "                (len(exp_replay), agent.epsilon))\n",
        "\n",
        "            plt.figure(figsize=[16, 9])\n",
        "\n",
        "            plt.subplot(2, 2, 1)\n",
        "            plt.title(\"Mean reward per life\")\n",
        "            plt.plot(mean_rw_history)\n",
        "            plt.grid()\n",
        "\n",
        "            assert not np.isnan(td_loss_history[-1])\n",
        "            plt.subplot(2, 2, 2)\n",
        "            plt.title(\"TD loss history (smoothened)\")\n",
        "            plt.plot(utils.smoothen(td_loss_history))\n",
        "            plt.grid()\n",
        "\n",
        "            plt.subplot(2, 2, 3)\n",
        "            plt.title(\"Initial state V\")\n",
        "            plt.plot(initial_state_v_history)\n",
        "            plt.grid()\n",
        "\n",
        "            plt.subplot(2, 2, 4)\n",
        "            plt.title(\"Grad norm history (smoothened)\")\n",
        "            # print(grad_norm_history)\n",
        "            grad_norm_history1 = [i.to('cpu') for i in grad_norm_history]\n",
        "            plt.plot(smoothen(grad_norm_history1))\n",
        "            plt.grid()\n",
        "\n",
        "            plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NK1iL9j3X90t"
      },
      "source": [
        "Agent is evaluated for 1 life, not for a whole episode of 5 lives. Rewards in evaluation are also truncated. Cuz this is what environment the agent is learning in and in this way mean rewards per life can be compared with initial state value\n",
        "\n",
        "**The goal is to get 15 points in the real env**. So 3 or better 4 points in the preprocessed one will probably be enough. You can interrupt learning then."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdfLFeU7X90u"
      },
      "source": [
        "Final scoring is done on a whole episode with all 5 lives."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qK5bw_arX90u",
        "outputId": "1cb3442e-7d51-4cef-a731-8715f1bdaa05"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.8/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.8/dist-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
            "  logger.deprecation(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "final score: 21.0\n",
            "Cool!\n"
          ]
        }
      ],
      "source": [
        "final_score = evaluate(\n",
        "  make_env(clip_rewards=False, seed=9),\n",
        "    agent, n_games=30, greedy=True, t_max=10 * 1000\n",
        ") * n_lives\n",
        "print('final score:', final_score)\n",
        "assert final_score >= 15, 'not as cool as DQN can'\n",
        "print('Cool!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueGODG9XX90u"
      },
      "source": [
        "## How to interpret plots:\n",
        "\n",
        "This aint no supervised learning so don't expect anything to improve monotonously. \n",
        "* **TD loss** is the MSE between agent's current Q-values and target Q-values. It may slowly increase or decrease, it's ok. The \"not ok\" behavior includes going NaN or stayng at exactly zero before agent has perfect performance.\n",
        "* **grad norm** just shows the intensivity of training. Not ok is growing to values of about 100 (or maybe even 50) though it depends on network architecture.\n",
        "* **mean reward** is the expected sum of r(s,a) agent gets over the full game session. It will oscillate, but on average it should get higher over time (after a few thousand iterations...). \n",
        " * In basic q-learning implementation it takes about 40k steps to \"warm up\" agent before it starts to get better.\n",
        "* **Initial state V** is the expected discounted reward for episode in the oppinion of the agent. It should behave more smoothly than **mean reward**. It should get higher over time but sometimes can experience drawdowns because of the agaent's overestimates.\n",
        "* **buffer size** - this one is simple. It should go up and cap at max size.\n",
        "* **epsilon** - agent's willingness to explore. If you see that agent's already at 0.01 epsilon before it's average reward is above 0 - it means you need to increase epsilon. Set it back to some 0.2 - 0.5 and decrease the pace at which it goes down.\n",
        "* Smoothing of plots is done with a gaussian kernel\n",
        "\n",
        "At first your agent will lose quickly. Then it will learn to suck less and at least hit the ball a few times before it loses. Finally it will learn to actually score points.\n",
        "\n",
        "**Training will take time.** A lot of it actually. Probably you will not see any improvment during first **150k** time steps (note that by default in this notebook agent is evaluated every 5000 time steps).\n",
        "\n",
        "But hey, long training time isn't _that_ bad:\n",
        "![img](https://github.com/yandexdataschool/Practical_RL/raw/master/yet_another_week/_resource/training.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkceOPs_X90w"
      },
      "source": [
        "## About hyperparameters:\n",
        "\n",
        "The task has something in common with supervised learning: loss is optimized through the buffer (instead of Train dataset). But the distribution of states and actions in the buffer **is not stationary** and depends on the policy that generated it. It can even happen that the mean TD error across the buffer is very low but the performance is extremely poor (imagine the agent collecting data to the buffer always manages to avoid the ball).\n",
        "\n",
        "* Total timesteps and training time: It seems to be so huge, but actually it is normal for RL.\n",
        "\n",
        "* $\\epsilon$ decay shedule was taken from the original paper and is like traditional for epsilon-greedy policies. At the beginning of the training the agent's greedy policy is poor so many random actions should be taken.\n",
        "\n",
        "* Optimizer: In the original paper RMSProp was used (they did not have Adam in 2013) and it can work not worse than Adam. For us Adam was default and it worked.\n",
        "\n",
        "* lr: $10^{-3}$ would probably be too huge\n",
        "\n",
        "* batch size: This one can be very important: if it is too small the agent can fail to learn. Huge batch takes more time to process. If batch of size 8 can not be processed on the hardware you use take 2 (or even 4) batches of size 4, divide the loss on them by 2 (or 4) and make optimization step after both backward() calls in torch.\n",
        "\n",
        "* target network update frequency: has something in common with learning rate. Too frequent updates can lead to divergence. Too rare can lead to slow leraning. For millions of total timesteps thousands of inner steps seem ok. One iteration of target network updating is an iteration of the (this time approximate) $\\gamma$-compression that stands behind Q-learning. The more inner steps it makes the more accurate is the compression.\n",
        "* max_grad_norm - just huge enough. In torch clip_grad_norm also evaluates the norm before clipping and it can be convenient for logging."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zngKx1ppX90x"
      },
      "source": [
        "### Video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 688
        },
        "id": "tP1g2Oud0rZ5",
        "outputId": "f2418e75-edfb-4f9b-c3d6-d434ac53ef35"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/gym/wrappers/monitoring/video_recorder.py:78: DeprecationWarning: \u001b[33mWARN: Recording ability for environment BreakoutNoFrameskip-v4 initialized with `render_mode=None` is marked as deprecated and will be removed in the future.\u001b[0m\n",
            "  logger.deprecation(\n",
            "/usr/local/lib/python3.8/dist-packages/gym/wrappers/monitoring/video_recorder.py:101: DeprecationWarning: \u001b[33mWARN: <class 'gym.wrappers.monitoring.video_recorder.VideoRecorder'> is marked as deprecated and will be removed in the future.\u001b[0m\n",
            "  logger.deprecation(\n",
            "/usr/local/lib/python3.8/dist-packages/gym/core.py:43: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  deprecation(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<video width=400 controls><source src=\"data:video/mp4;base64,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\" type=\"video/mp4\"></video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from gym.wrappers.monitoring.video_recorder import VideoRecorder\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "def render_mp4(videopath: str) -> str:\n",
        "  \"\"\"\n",
        "  Gets a string containing a b4-encoded version of the MP4 video\n",
        "  at the specified path.\n",
        "  \"\"\"\n",
        "  mp4 = open(videopath, 'rb').read()\n",
        "  base64_encoded_mp4 = b64encode(mp4).decode()\n",
        "  return f'<video width=400 controls><source src=\"data:video/mp4;' \\\n",
        "         f'base64,{base64_encoded_mp4}\" type=\"video/mp4\"></video>'\n",
        "\n",
        "after_training = \"after_training.mp4\"\n",
        "after_video = VideoRecorder(env, after_training)\n",
        "observation = env.reset()\n",
        "done = False\n",
        "while not done:\n",
        "  env.render(\"rgb_array\")\n",
        "  after_video.capture_frame()\n",
        "\n",
        "  qvalues = agent.get_qvalues([observation])\n",
        "  action = agent.sample_actions(qvalues)[0]\n",
        "  # action = agent. .compute_action(observation)\n",
        "  observation, reward, done, info = env.step(action)\n",
        "after_video.close()\n",
        "env.close()\n",
        "# You should get a video similar to the one below. \n",
        "html = render_mp4(after_training)\n",
        "HTML(html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VWsPWc6X900"
      },
      "source": [
        "## Let's have a closer look at this.\n",
        "\n",
        "If average episode score is below 200 using all 5 lives, then probably DQN has not converged fully. But anyway let's make a more complete record of an episode."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZA3UXQEX901",
        "outputId": "e6d249aa-2e4b-40e0-e52c-4157b73cc452"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.8/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.8/dist-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
            "  logger.deprecation(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total reward for life: 5.0\n",
            "states\n",
            "v_mc\n",
            "v_agent\n",
            "q_spreads\n",
            "td_errors\n",
            "rewards\n",
            "episode_finished\n"
          ]
        }
      ],
      "source": [
        "eval_env = make_env(clip_rewards=False)\n",
        "record = utils.play_and_log_episode(eval_env, agent)\n",
        "print('total reward for life:', np.sum(record['rewards']))\n",
        "for key in record:\n",
        "    print(key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "iRswcogsX901",
        "outputId": "79157738-5739-4cf5-f288-7d6417635b9e"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig = plt.figure(figsize=(5, 5))\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "\n",
        "ax.scatter(record['v_mc'], record['v_agent'])\n",
        "ax.plot(sorted(record['v_mc']), sorted(record['v_mc']),\n",
        "       'black', linestyle='--', label='x=y')\n",
        "\n",
        "ax.grid()\n",
        "ax.legend()\n",
        "ax.set_title('State Value Estimates')\n",
        "ax.set_xlabel('Monte-Carlo')\n",
        "ax.set_ylabel('Agent')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27W78ZZLX901"
      },
      "source": [
        "$\\hat V_{Monte-Carlo}(s_t) = \\sum_{\\tau=0}^{episode~end} \\gamma^{\\tau-t}r_t$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2OdrwyGX902"
      },
      "source": [
        "Is there a big bias? It's ok, anyway it works."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypNUGgvAX903"
      },
      "source": [
        "## Bonus I (2 pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mz5TtM7MX903"
      },
      "source": [
        "**1.** Plot several (say 3) states with high and low spreads of Q estimate by actions i.e.\n",
        "$$\\max_a \\hat Q(s,a) - \\min_a \\hat Q(s,a)\\$$\n",
        "Please take those states from different episodes to make sure that the states are really different.\n",
        "\n",
        "What should high and low spread mean at least in the world of perfect Q-fucntions?\n",
        "\n",
        "Comment the states you like most.\n",
        "\n",
        "**2.** Plot several (say 3) states with high td-error and several states with high values of\n",
        "$$| \\hat V_{Monte-Carlo}(s) - \\hat V_{agent}(s)|,$$ \n",
        "$$\\hat V_{agent}(s)=\\max_a \\hat Q(s,a).$$ Please take those states from different episodes to make sure that the states are really different. From what part (i.e. beginning, middle, end) of an episode did these states come from?\n",
        "\n",
        "Comment the states you like most."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39DW20vAX904"
      },
      "outputs": [],
      "source": [
        "from utils import play_and_log_episode, img_by_obs\n",
        "\n",
        "<YOUR CODE>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhQRHE7SX904"
      },
      "source": [
        "## Bonus II (1-5 pts). Get High Score!\n",
        "\n",
        "1 point to you for each 50 points of your agent. Truncated by 5 points. Starting with 50 points, **not** 50 + threshold.\n",
        "\n",
        "One way is to train for several days and use heavier hardware (why not actually).\n",
        "\n",
        "Another way is to apply modifications (see **Bonus III**)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUNgJbpWX904"
      },
      "source": [
        "## Bonus III (2+ pts). Apply modifications to DQN.\n",
        "\n",
        "For inspiration see [Rainbow](https://arxiv.org/abs/1710.02298) - a version of q-learning that combines lots of them.\n",
        "\n",
        "Points for Bonus II and Bonus III fully stack. So if modified agent gets score 250+ you get 5 pts for Bonus II + points for modifications. If the final score is 40 then you get the points for modifications.\n",
        "\n",
        "\n",
        "Some modifications:\n",
        "* [Prioritized experience replay](https://arxiv.org/abs/1511.05952) (5 pts for your own implementation, 3 pts for using a ready one)\n",
        "* [double q-learning](https://arxiv.org/abs/1509.06461) (2 pts)\n",
        "* [dueling q-learning](https://arxiv.org/abs/1511.06581) (2 pts)\n",
        "* multi-step heuristics (see [Rainbow](https://arxiv.org/abs/1710.02298)) (3 pts)\n",
        "* [Noisy Nets](https://arxiv.org/abs/1706.10295) (3 pts)\n",
        "* [distributional RL](https://arxiv.org/abs/1707.06887)(distributional and distributed stand for different things here) (5 pts)\n",
        "* Other modifications (2+ pts depending on complexity)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBNDnGEdX907"
      },
      "source": [
        "## Bonus IV (4+ pts). Distributed RL.\n",
        "\n",
        "Solve the task in a distributed way. It can strongly speed up learning. See [article](https://arxiv.org/pdf/1602.01783.pdf) or some guides."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ck5KWJtX907"
      },
      "source": [
        "**As usual bonus points for all the tasks fully stack.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6PNPXHMqX908"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
